---
title: "European Election Campaign Study 2014"
author: Katerin Kunfermann (), Haylee Kelsall (11665424), Louelle Pesurnaij (10750886),
  Matteo Rinaldi ()
date: "31 January 2019"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


#@@Jobs before handing in: 
#Check code is actually tide for the group part. Is it as concise as possible? e.g. replace nl1a, nl1b, nl1c with nl1a:nl1c. 
#Someone needs to go through CA code, and check 'ID' is in everything. Unforutnately V2 was not a unique ID but instead unique only to coders GAH
#Check there is enough detail given in tiying explanations, including e.g. 'viewed it using head(x) and checked compared to...'
#Check entire thing ACTUALLY runs
#Check spelling, cntrl+f search for @ signs notes to be done/removed
#WRITE TEXT INTRODUCING THE OVERALL INFOGRAPHIC... Somehow
#Do all visualisation fit together somehow in terms of style?
#All names on the document? Title? Date? Etc. 
#How does the text knit? 
#Set code chunks to echo = False
#@@More to be added to list of shit to do... 

##CONTENT ANALYSIS SET STILL NEEDS TO BE CHECKED FOR OTHER RULES OF TIDYING!!!!!!!!


```



```{r import survey data and access packages, include=FALSE, message = FALSE, warning = FALSE}
library(tidyverse) #access tidyverse
library(lubridate) #lubridate
library(plyr) 
library(plotly)
library(ggthemes)


#Stripper function used in some data work

stripper <- function(string){ 
  str_extract(string, "\\-*\\d+\\.*\\d*")
} 

CA <- read_csv("Dataset MCA EPE 2014 NL FINAL.csv") #Read content analysis file, store under CA
# @ later remove this so also contetn analysis is imported here

ESS <- read_csv("All waves GENERAL.csv") # read survey file, store under ESS (Election Study Survey)

#Tidying the data set. Step ONE: Seperate respondent fixed characteristics, with help of code book.
#Examples of these: demographics, big 5 personality traits etc. Here the RESPONDENT is the unit. 
#We also want to include here a column for the waves which the participant was in, we only have the 'GENERAL' panel data so not neccessary to create additional columns for other panels. 

ESS %>%
  summarise(n_RESPS = n_distinct(RESPNR)) #Check all respondent IDs unique. Respondent ID will be #used as our primary key in this table.
# @ wave weighting should probabbly be in the wave'd variables seeing as they apply to each wave, fix this later @H

#tidy columns respondent ID and Waves
ESS %>% count(WAVES) #First count the number of respondents participating in each level of 'WAVES'.

#Wave 1
ESS$wave1 <- ifelse(ESS$WAVES == "All waves", 1, ifelse(ESS$WAVES == "Only wave 1", 1, ifelse(ESS$WAVES == "Wave 1 and 2", 1, ifelse(ESS$WAVES == "Wave 1, 2 and 3", 1, 0)))) 
#Create new column called "wave1" in ESS, assign the value 1 = YES 0 = NO. (Note all participants were in at least wave1) 

#Wave 2
ESS$wave2 <- ifelse(ESS$WAVES == "All waves", 1, ifelse(ESS$WAVES == "Wave 1 and 2", 1, ifelse(ESS$WAVES == "Wave 1, 2 and 3", 1, 0))) #Create new column called "wave2" in ESS, assign the value 1 = YES if respondent participated in wave 2, 0 = NO. 

#Wave 3
ESS$wave3 <- ifelse(ESS$WAVES == "All waves", 1, ifelse(ESS$WAVES == "Wave 1, 2 and 3", 1, 0)) 
#Create new column called "wave3" in ESS, assign the value 1 = YES if respondent participated in wave 3, 0 = NO. 

#Wave 4
ESS$wave4 <- ifelse(ESS$WAVES == "All waves", 1, 0) #Create new column called "wave4" in ESS, assign the value 1 = YES if respondent participated in wave 4, 0 = NO.

RESP_DEMOG <- ESS %>%
  group_by(INTNR, RESPNR,	SAMPLE,	WAVES,	GEWICHTA1_w1,	GEWICHTA1_w2,	GEWICHTA1_w3,	GEWICHTA1_w4,	GSL,	LFT,	OPLA,	NIELSENCBS,	GEZINSGROOTTE,	POL2012, w1_q5_1, w1_q5_2, w1_q5_3, w1_q5_4, w1_q17_1, w1_q17_2, w1_q17_3, w1_q17_4, w1_q23, w1_q24_1, w1_q24_2, w1_q24_3, w1_q29, w1_q30_1,w1_q30_2,	w1_q30_3,	w1_q30_4,	w1_q30_5,	w1_q30_6,	w1_q30_7,	w1_q30_8,	w1_q30_9,	w1_q30_10,	w1_q30_11, w1_q31_1,	w1_q31_2,	w1_q31_3,	w1_q31_4,	w1_q31_5,	w1_q31_6,	w1_q31_7,	w1_q31_8,	w1_q31_9,	w1_q32_1,	w1_q32_2,	w1_q32_3,	w1_q32_4, w1_q57_1,	w1_q57_2,	w1_q57_3,	w1_q57_4,	w1_q57_5,	w1_q57_6,	w1_q57_7,	w1_q57_8,	w1_q58_1,	w1_q58_2,	w1_q58_3,	w1_q58_4,	w1_q58_5,	w1_q58_6,	w1_q58_7,	w1_q58_8,	w1_q58_9,	w1_q58_10,	w1_q59,	w1_q60,	w1_q61,	w1_q62,	w1_q64,	w1_q65,	w1_q66,	w1_q67,	w1_q68,	w1_q68_YES, w2_q25,	w2_q26_1,	w2_q26_2,	w2_q26_3,	w2_q26_4,	w2_q26_5,	w2_q26_6,	w2_q26_7,	w2_q26_8,	w2_q26_9,	w2_q26_10,	w2_q26_11,	w2_q27_1,	w2_q27_2,	w2_q27_3,	w2_q27_4,	w2_q27_5,	w2_q27_6,	w2_q27_7,	w2_q27_8,	w2_q27_9,	w2_q28_1,	w2_q28_2,	w2_q28_3,	w2_q28_4,	w2_q28_5,	w2_q28_6,	w2_q28_7,	w2_q28_8,	w2_q28_9,	w2_q28_10,	w2_q28_11,	w2_q29,	w2_q30,	w2_q30_OTHER_LOCAL,	w2_q30_OTHER,	w2_q31,	w2_q32_1,	w2_q32_2,	w2_q32_3,	w2_q32_4,	w2_q32_5,	w2_q32_OTHER,	w2_q33_1,	w2_q33_2,	w2_q33_3,	w2_q33_4,	w2_q33_5,	w2_q33_6,	w2_q33_7,	w2_q33_8,	w2_q33_9,	w2_q33_10,	w2_q33_11,	w2_q33_12,	w2_q33_13,	w2_q33_14,	w2_q33_OTHER_LOCAL,	w2_q33_OTHER,	w2_q50_1,	w2_q50_2,	w2_q50_3,	w2_q50_4,	w2_q50_5,	w2_q50_6,	w2_q51,	w2_q52_1,	w2_q52_2,	w2_q52_3,	w2_q52_4,	w2_q52_5,	w2_q53_1,	w2_q53_2,	w2_q54,	w2_q55,	w2_q56_1,	w2_q56_2,	w2_q56_3,	w2_q56_4, w2_q61_1,	w2_q61_2,	w2_q62_CONDITION1,	w2_q62_CONDITION2, w2_q63,	w2_q65, w3_q49TRUE_1,	w3_q49TRUE_2,	w3_q49TRUE_3,	w3_q49TRUE_4,	w3_q49TRUE_5,	w3_q49TRUE_6,	w3_q49TRUE_7,	w3_q49_1,	w3_q49_2,	w3_q49_3,	w3_q49_4,	w3_q49_5,	w3_q49_6,	w3_q49_7, w3_q56_CONDITION1_1,	w3_q56_CONDITION1_2,	w3_q56_CONDITION1_3,	w3_q56_CONDITION1_4,	w3_q56_CONDITION2_1,	w3_q56_CONDITION2_2,	w3_q56_CONDITION2_3,	w3_q56_CONDITION2_4,	w3_q56_TIMESTAMP, w3_q59_1,	w3_q59_2,	w3_q59_3,	w3_q60_1,	w3_q60_2,	w3_q60_3,	w3_q60_4, w4_q7,	w4_q8,	w4_q9, w4_q27, w4_q41_1,	w4_q41_2,	w4_q41_3,	w4_q41_4,	w4_q41_5,	w4_q41_6,	w4_q41_7,	w4_q41_8,	w4_q41_9,	w4_q41_10,	w4_q41_11, w4_q41_12,  w4_q43_1,	w4_q43_2,	w4_q43_3,	w4_q43_4,	w4_q43_5,	w4_q43_6,	w4_q43_7,	w4_q43_8,	w4_q43_9,	w4_q43_10,	w4_q43_11,	w4_q43_12, w4_q51_1,	w4_q51_2,	w4_q51_3,	w4_q51_4,	w4_q51_5,	w4_q51_OTHER,	w4_q52_1,	w4_q52_2,	w4_q52_3,	w4_q52_4,	w4_q52_5,	w4_q52_6,	w4_q52_7,	w4_q52_8,	w4_q52_9,	w4_q52_10,	w4_q52_11,	w4_q52_12,	w4_q52_13,	w4_q52_OTHER, w4_q57, w4_q62_1,	w4_q62_2,	w4_q62_3,	w4_q62_4,	w4_q62_5,	w4_q62_6,	w4_q62_7) %>%
summarise()
RESP_DEMOG #Now we have a table with all fixed characteristics of respondents. We still need to check every single variable that it meets rules of tidy data even thouh now at least 'each unit has its own table' is PARTLY fulfilled with this table @@

#@@ NOTE!!! SOME VARIABLES ABOVE HAVE BEEN RECODED already into standard variable names already such as w1_q61 is actualy OPLA (opleiding) 

#Change W3_Q56
RESP_DEMOG_test <- RESP_DEMOG %>% group_by(RESPNR, w3_q56_CONDITION1_1, w3_q56_CONDITION1_2, w3_q56_CONDITION1_3, w3_q56_CONDITION1_4, w3_q56_CONDITION2_1, w3_q56_CONDITION2_2, w3_q56_CONDITION2_3, w3_q56_CONDITION2_4) %>% select(RESPNR, w3_q56_CONDITION1_1, w3_q56_CONDITION1_2, w3_q56_CONDITION1_3, w3_q56_CONDITION1_4, w3_q56_CONDITION2_1, w3_q56_CONDITION2_2, w3_q56_CONDITION2_3, w3_q56_CONDITION2_4)

#Splitting the Experiment-data
RESP_DEMOG$W3_Q56_CONDITION <- ifelse(!is.na(RESP_DEMOG$w3_q56_CONDITION1_1), 1, ifelse(!is.na(RESP_DEMOG$w3_q56_CONDITION1_2), 1, ifelse(!is.na(RESP_DEMOG$w3_q56_CONDITION1_3), 1, ifelse(!is.na(RESP_DEMOG$w3_q56_CONDITION1_4), 1, ifelse(!is.na(RESP_DEMOG$w3_q56_CONDITION2_1), 2, ifelse(!is.na(RESP_DEMOG$w3_q56_CONDITION2_2), 2, ifelse(!is.na(RESP_DEMOG$w3_q56_CONDITION2_3), 2, ifelse(!is.na(RESP_DEMOG$w3_q56_CONDITION2_4), 2, NA)))))))) 

```


```{r Spread the waveeeeees, include=FALSE, message = FALSE, warning = FALSE}
#select relevant variables for all waves
ESSclean <- select(ESS, -c(INTNR, SAMPLE,	GEWICHTA1_w1,	GEWICHTA1_w2,	GEWICHTA1_w3,	GEWICHTA1_w4,	GSL,	LFT,	OPLA,	NIELSENCBS,	GEZINSGROOTTE,	POL2012, w1_q5_1, w1_q5_2, w1_q5_3, w1_q5_4, w1_q17_1, w1_q17_2, w1_q17_3, w1_q17_4, w1_q23, w1_q24_1, w1_q24_2, w1_q24_3, w1_q29, w1_q30_1,w1_q30_2,	w1_q30_3,	w1_q30_4,	w1_q30_5,	w1_q30_6,	w1_q30_7,	w1_q30_8,	w1_q30_9,	w1_q30_10,	w1_q30_11, w1_q31_1,	w1_q31_2,	w1_q31_3,	w1_q31_4,	w1_q31_5,	w1_q31_6,	w1_q31_7,	w1_q31_8,	w1_q31_9,	w1_q32_1,	w1_q32_2,	w1_q32_3,	w1_q32_4, w1_q57_1,	w1_q57_2,	w1_q57_3,	w1_q57_4,	w1_q57_5,	w1_q57_6,	w1_q57_7,	w1_q57_8,	w1_q58_1,	w1_q58_2,	w1_q58_3,	w1_q58_4,	w1_q58_5,	w1_q58_6,	w1_q58_7,	w1_q58_8,	w1_q58_9,	w1_q58_10,	w1_q59,	w1_q60,	w1_q61,	w1_q62,	w1_q64,	w1_q65,	w1_q66,	w1_q67,	w1_q68,	w1_q68_YES, w2_q25,	w2_q26_1,	w2_q26_2,	w2_q26_3,	w2_q26_4,	w2_q26_5,	w2_q26_6,	w2_q26_7,	w2_q26_8,	w2_q26_9,	w2_q26_10,	w2_q26_11,	w2_q27_1,	w2_q27_2,	w2_q27_3,	w2_q27_4,	w2_q27_5,	w2_q27_6,	w2_q27_7,	w2_q27_8,	w2_q27_9,	w2_q28_1,	w2_q28_2,	w2_q28_3,	w2_q28_4,	w2_q28_5,	w2_q28_6,	w2_q28_7,	w2_q28_8,	w2_q28_9,	w2_q28_10,	w2_q28_11,	w2_q29,	w2_q30,	w2_q30_OTHER_LOCAL,	w2_q30_OTHER,	w2_q31,	w2_q32_1,	w2_q32_2,	w2_q32_3,	w2_q32_4,	w2_q32_5,	w2_q32_OTHER,	w2_q33_1,	w2_q33_2,	w2_q33_3,	w2_q33_4,	w2_q33_5,	w2_q33_6,	w2_q33_7,	w2_q33_8,	w2_q33_9,	w2_q33_10,	w2_q33_11,	w2_q33_12,	w2_q33_13,	w2_q33_14,	w2_q33_OTHER_LOCAL,	w2_q33_OTHER,	w2_q50_1,	w2_q50_2,	w2_q50_3,	w2_q50_4,	w2_q50_5,	w2_q50_6,	w2_q51,	w2_q52_1,	w2_q52_2,	w2_q52_3,	w2_q52_4,	w2_q52_5,	w2_q53_1,	w2_q53_2,	w2_q54,	w2_q55,	w2_q56_1,	w2_q56_2,	w2_q56_3,	w2_q56_4, w2_q61_1,	w2_q61_2,	w2_q62_CONDITION1,	w2_q62_CONDITION2, w2_q63,	w2_q65, w3_q49TRUE_1,	w3_q49TRUE_2,	w3_q49TRUE_3,	w3_q49TRUE_4,	w3_q49TRUE_5,	w3_q49TRUE_6,	w3_q49TRUE_7,	w3_q49_1,	w3_q49_2,	w3_q49_3,	w3_q49_4,	w3_q49_5,	w3_q49_6,	w3_q49_7, w3_q56_CONDITION1_1,	w3_q56_CONDITION1_2,	w3_q56_CONDITION1_3,	w3_q56_CONDITION1_4,	w3_q56_CONDITION2_1,	w3_q56_CONDITION2_2,	w3_q56_CONDITION2_3,	w3_q56_CONDITION2_4,	w3_q56_TIMESTAMP, w3_q59_1,	w3_q59_2,	w3_q59_3,	w3_q60_1,	w3_q60_2,	w3_q60_3,	w3_q60_4, w4_q7,	w4_q8,	w4_q9, w4_q27, w4_q41_1,	w4_q41_2,	w4_q41_3,	w4_q41_4,	w4_q41_5,	w4_q41_6,	w4_q41_7,	w4_q41_8,	w4_q41_9,	w4_q41_10,	w4_q41_11, w4_q41_12,  w4_q43_1,	w4_q43_2,	w4_q43_3,	w4_q43_4,	w4_q43_5,	w4_q43_6,	w4_q43_7,	w4_q43_8,	w4_q43_9,	w4_q43_10,	w4_q43_11,	w4_q43_12, w4_q51_1,	w4_q51_2,	w4_q51_3,	w4_q51_4,	w4_q51_5,	w4_q51_OTHER,	w4_q52_1,	w4_q52_2,	w4_q52_3,	w4_q52_4,	w4_q52_5,	w4_q52_6,	w4_q52_7,	w4_q52_8,	w4_q52_9,	w4_q52_10,	w4_q52_11,	w4_q52_12,	w4_q52_13,	w4_q52_OTHER, w4_q57, w4_q62_1,	w4_q62_2,	w4_q62_3,	w4_q62_4,	w4_q62_5,	w4_q62_6,	w4_q62_7, wave1, wave2, wave3, wave4))

#Change values 1 (=TRUE) to 2 (=participates in wave 2)
#Wave 1
ESSclean$wave1 <- ifelse(ESS$wave1 == 1, 1, NA)
#Wave 2
ESSclean$wave2 <- ifelse(ESS$wave2 == 1, 2, NA)
#Wave 3
ESSclean$wave3 <- ifelse(ESS$wave3 == 1, 3, NA)
#Wave 4
ESSclean$wave4 <- ifelse(ESS$wave4 == 1, 4, NA)

#Create one out of Wave 1, 2, 3, 4
ESSclean <- ESSclean %>% gather(Wave, Wavevalue, wave1:wave4, na.rm = TRUE, convert = FALSE, factor_key = FALSE)



#remove WAVES and Wave columns
ESSclean$Wave <- NULL

# Clean up date-variables
ESSclean$date <- ifelse(ESSclean$Wavevalue == 1, ESSclean$w1_DATUM, ifelse(ESSclean$Wavevalue == 2, ESSclean$w2_DATUM, ifelse(ESSclean$Wavevalue == 3, ESSclean$w3_DATUM, ifelse(ESSclean$Wavevalue == 4, ESSclean$w4_DATUM, NA))))

# Change date-variable from character to actual date
ESSclean <- transform(ESSclean, date = as.Date(as.character(date), "%Y%m%d"))
```

```{r - CA tidying chunk, include=FALSE, message = FALSE, warning = FALSE}

library(lubridate)

#First parse date in original object so all latter tables will already have a 'date' column. day = V3a, month = V3b, year = V3c.
CA$date <- with(CA, dmy(sprintf('%02d%02d%02d', V3a, V3b, V3c))) #Checked in console!
#Also need to add unique id number to each item
CA$ID <- seq.int(nrow(CA))

CA$ID

#Creating table for fixed characteristics relevant to all, i.e. items asked to everything. Checked using console. 
ALL_FIXED <- CA %>% 
  select(ID, V1,	V2,	V3a,	V3b,	V3c, date,	V4,	V5, V6,	V6_cleaned, NL1a : NL1f, V7, V8a, V8b, V9,V11, V12, V13, V14, V15a_TEXT : V15f_TEXT, V15_a_cleaned : V15_f_cleaned,  V16a : V16f, NL7a : NL7e, NL24, NL25, NL26, NL27, NL28a, NL28b, NL29a : NL29g, NL30, NL31, NL32a : NL32g, NL33) #Include V's asked for all

#pull apart column V6_cleaned into two columns by splitting at the ":" 
ALL_FIXED <- separate(ALL_FIXED, V6_cleaned, into = c("V6Topic", "V6Topicdescription"), sep = ":")

#Creating Newspaper fixed characteristics table. Note: nu.nl is included as a newspaper, because it is treated as one in the codebook. Keeping V4 as article ID for primary key, also keeping V4 (outlet) as may be useful also. In addition, note that the belgium outlets are included as they're treated as newspapers. These
#need to probably be removed if neccessary during later analysis!
CA_FIXED_NP <- CA %>%
  filter(V4 != "NOS Journaal" & V4 != "RTL Nieuws")%>% #Exclude (filter out) the two TV channels
  select(ID, V2,	V4, NP1,	NP2,	NP3,	NP4,	NP5,	NP6,	NP7) 

#@@This should be edited if we claim PVV+50PLUS table is also similar@@@Creating Table for the Muslim/Polish questions, which have very different structure to the rest of data
#NL2_1_1: NL2_4_3 = the table questions on p. 11 of codebook concerning muslims, and NL4 starting items are
#for the sae q's but Polish. Articles had these questions based on their primary topic, as stated on p. 10 of 
# the codebook '(V6) = [0124 | 0501 thru 0507 | 0704 | 1204 | 1603]'. Therefore only articles/news with these 
#topics are included in this table. It also includes their ID number and primary topic as keys @@??

MUS_POL <- CA %>%
  select(ID, V2, V6, NL2_1_1 : NL2_4_3, NL3, NL4_1_1 : NL4_4_3, NL5) %>%
  filter(V6 == "Economy: Free movement of people within the EU (common market: including the Schengen agreement)" | V6 == "Immigration : EU immigration policy - regulating immigration from outside the EU (e.g. refugees, asylum, EU border" | V6 == "Immigration : Migration / immigration policy – regulating migration within the EU (e.g. labour migration from East" | V6 == "Immigration : Immigration policy (non-EU) - regulating immigration from outside the EU" | V6 == "Immigration : Immigrant integration" | V6 =="Immigration : Multiculturalism (cultural diversity, cultural plurality)" | V6 == "Immigration : Anti-Islam" | V6 == "Immigration : Other immigration topics" | V6 == "Culture and Other: Religion" | V6 == "Citizens’ rights: Immigrant rights" | V6 == "Elections: Media coverage of the campaign") 

#create variable "Origins" as factor with levels of different Nationalities: Muslims / followers of Islam, Moroccan origins, Turkish origins, Other national origins, Poles, Other specific Middle or Eastern nationals (from the EU), Middle and/or Eastern Europeans in general  (from the EU), Eastern European, but not EU (Russia, Ukraine, Belarus, Moldova)

#create variable "origin" with value 1 to 8 for different origins in variables NL2_1_1:NL2_4_3 and NL4_1_1:NL4_4_3

#levels: 1 = Muslims/followers of Islam, 2 = Moroccan origins, 3 = Turkish origins, 4 = Other national origins, 5 = Poles, 6 = other specific middle or eastern nationals (from the EU)

getOrigin <- function(datatable) {
  case_when(
    datatable$NL2_1_1 == 1 ~ 1,
    datatable$NL2_1_2 == 1 ~ 1,
    datatable$NL2_1_3 == 1 ~ 1, 
    datatable$NL2_2_1 == 1 ~ 2,
    datatable$NL2_2_2 == 1 ~ 2,
    datatable$NL2_2_3 == 1 ~ 2, 
    datatable$NL2_3_1 == 1 ~ 3,
    datatable$NL2_3_2 == 1 ~ 3,
    datatable$NL2_3_3 == 1 ~ 3,
    datatable$NL2_4_1 == 1 ~ 4,
    datatable$NL2_4_2 == 1 ~ 4,
    datatable$NL2_4_3 == 1 ~ 4,
    datatable$NL4_1_1 == 1 ~ 5,
    datatable$NL4_1_2 == 1 ~ 5,
    datatable$NL4_1_3 == 1 ~ 5, 
    datatable$NL4_2_1 == 1 ~ 6,
    datatable$NL4_2_2 == 1 ~ 6,
    datatable$NL4_2_3 == 1 ~ 6,
    datatable$NL4_3_1 == 1 ~ 7,
    datatable$NL4_3_2 == 1 ~ 7,
    datatable$NL4_3_3 == 1 ~ 7, 
    datatable$NL4_4_1 == 1 ~ 8,
    datatable$NL4_4_2 == 1 ~ 8,
    datatable$NL4_4_3 == 1 ~ 8
    )
}

#call function origin
origin <-  getOrigin(MUS_POL)
MUS_POL$origin <- origin

#do the same for location
#Levels: 1 = in the Netherlands, 2 = In another country, 3 = in the "home" country

getLocation <- function(datatable) {
  case_when(
    datatable$NL2_1_1 == 1 ~ 1,
    datatable$NL2_1_2 == 1 ~ 2,
    datatable$NL2_1_3 == 1 ~ 3,
    datatable$NL2_2_1 == 1 ~ 1,
    datatable$NL2_2_2 == 1 ~ 2,
    datatable$NL2_2_3 == 1 ~ 3,
    datatable$NL2_3_1 == 1 ~ 1,
    datatable$NL2_3_2 == 1 ~ 2,
    datatable$NL2_3_3 == 1 ~ 3,
    datatable$NL2_4_1 == 1 ~ 1,
    datatable$NL2_4_2 == 1 ~ 2,
    datatable$NL2_4_3 == 1 ~ 3,
    datatable$NL4_2_1 == 1 ~ 1,
    datatable$NL4_2_2 == 1 ~ 2,
    datatable$NL4_2_3 == 1 ~ 3,
    datatable$NL4_3_1 == 1 ~ 1,
    datatable$NL4_3_2 == 1 ~ 2,
    datatable$NL4_3_3 == 1 ~ 3,
    datatable$NL4_1_1 == 1 ~ 1,
    datatable$NL4_1_2 == 1 ~ 2,
    datatable$NL4_1_3 == 1 ~ 3
  )
}

#call function location
location <-  getLocation(MUS_POL)
MUS_POL$location <- location

#do the same for evaluation
#as in Codebook, Levels: 1 = no evaluation, 2 = negative, 3= rather negative, 4 = balanced/mixed, 5 = rather positive, 6 = positive

getEvaluation <- function(datatable) {
  case_when(
    !is.na(datatable$NL3) ~ datatable$NL3,
    !is.na(datatable$NL5) ~ datatable$NL5
  )
}

#call function evaluation
MUS_POL$evaluation <-  getEvaluation(MUS_POL)

#remove unnecessary variables
MUS_POL$NL2_1_1 <- NULL
MUS_POL$NL2_1_2 <- NULL
MUS_POL$NL2_1_3 <- NULL
MUS_POL$NL2_2_1 <- NULL
MUS_POL$NL2_2_2 <- NULL
MUS_POL$NL2_2_3 <- NULL
MUS_POL$NL2_3_1 <- NULL
MUS_POL$NL2_3_2 <- NULL
MUS_POL$NL2_3_3 <- NULL
MUS_POL$NL2_4_1 <- NULL
MUS_POL$NL2_4_2 <- NULL
MUS_POL$NL2_4_3 <- NULL

MUS_POL$NL3 <- NULL

MUS_POL$NL4_1_1 <- NULL
MUS_POL$NL4_1_2 <- NULL
MUS_POL$NL4_1_3 <- NULL
MUS_POL$NL4_2_1 <- NULL
MUS_POL$NL4_2_2 <- NULL
MUS_POL$NL4_2_3 <- NULL
MUS_POL$NL4_3_1 <- NULL
MUS_POL$NL4_3_2 <- NULL
MUS_POL$NL4_3_3 <- NULL
MUS_POL$NL4_4_1 <- NULL
MUS_POL$NL4_4_2 <- NULL
MUS_POL$NL4_4_3 <- NULL

MUS_POL$NL5 <- NULL

CA_FIXED_TV <- CA %>%
  filter(V4 == "NOS Journaal" | V4 == "RTL Nieuws")%>% #Exclude (filter out) the newspapers
  select(V2,	V4, TV1, TV2)


APRIL <- CA %>% #Table with variables coded only after april the 17th 
  select(V2, date, V9,	V9b,	V10a : V10c,	NL6_1_1 : NL6_3_4,	NL8a,	NL9a_1 : NL9a_5_TEXT, NL9b_1 : NL9b_5_TEXT, NL9c1 : NL9c5_TEXT, NL9d1 : NL9d5_TEXT,	NL10a : NL10d, NL11a1 : NL23d5_TEXT,	NL34 : NL41f, NL42a_a : NL42b_SP_f, NL43, NL44, NL45 : NL47) %>% 
filter(date >= as.Date("2014-04-17")) #and include cases only after filtered date, 17th April

  

```

```{r include=FALSE, message = FALSE, warning = FALSE}
#Creating a table for the PVV 50PLUS articles. 
#NOTE: This table @@was not further tidied as tidying would be similar to what was demonstrated with the MUS/POLE table above.
#Therefore, variables required by group members for their own analyses were tidied as required, rather than restructuring this entire table. 
#See for example PVVH table used by Haylee. 

PVV50 <- CA %>% #@@Ask whether we have to totally redo this table or not.
  filter(date >= as.Date("2014-04-17"))%>% #and include cases only after filtered date, 17th April
  dplyr::select(V2, NL8a, NL8b, NL8c, NL8d, NL9a_1:NL9a_5_TEXT, NL9b_1:NL9b_5_TEXT, NL9c1:NL9c5_TEXT, NL9d1:NL9d5_TEXT, NL10a, NL10b, NL10c, NL10d, NL11a1:NL11a5_TEXT, NL11b1:NL11b5_TEXT, NL11c1:NL11c5_TEXT, NL11d1:NL11d5_TEXT, NL12a, NL12b, NL12c, NL12d, NL13a1:NL13a5_TEXT, NL13b1:NL13b5_TEXT, NL13c1:NL13c5_TEXT, NL13d1:NL13d5_TEXT, NL14a, NL14b, NL14c, NL14d,  NL15a1:NL15a5_TEXT, NL15b1:NL15b5_TEXT, NL15c1:NL15c5_TEXT, NL15d1:NL15d5_TEXT, NL16a, NL16b, NL16c, NL16d, NL17a1:NL17a5_TEXT, NL17b1:NL17b5_TEXT, NL17c1:NL17c5_TEXT, NL17d1:NL17d5_TEXT, NL18a, NL18b, NL18c, NL18d, NL19a1:NL19a5_TEXT, NL19b1:NL19b5_TEXT, NL19c1:NL19c5_TEXT, NL19d1:NL19d5_TEXT, NL20a, NL20b, NL20c, NL20d, NL21a1:NL21a5_TEXT, NL21b1:NL21b5_TEXT, NL21c1:NL21c5_TEXT, NL21d1:NL21d5_TEXT, NL22a, NL22b, NL22c, NL22d, NL23a1:NL23a5_TEXT, NL23b1:NL23b5_TEXT, NL23c1:NL23c5_TEXT, NL23d1:NL23d5_TEXT)




  
```


## Louelle Pesurnaij
```{r Louelle Pesurnaij, echo = FALSE, message = FALSE, warning = FALSE}
#Create tables with variables for Louelle's visualization
Louelle_ESS <- ESSclean %>% select(RESPNR, Wavevalue, date, w1_q10_1, w1_q10_2, w1_q10_3,w1_q10_4, w2_q7_1, w2_q7_2, w2_q7_3, w2_q7_4, w3_q11_1, w3_q11_2, w3_q11_3, w3_q11_4, w4_q13_1, w4_q13_2, w4_q13_3, w4_q13_4, w1_q49_1, w1_q49_2, w1_q50_1, w1_q50_2, w1_q50_6, w2_q44_1, w2_q44_2, w2_q45_1, w2_q45_2, w2_q45_6, w3_q43_1, w3_q43_2, w3_q44_1, w3_q44_2, w3_q44_6, w4_q47_1, w4_q47_2, w4_q48_1, w4_q48_2, w4_q48_6,w1_q51_2, w2_q46_2, w3_q45_2, w4_q49_2)
Louelle_CA <- ALL_FIXED %>% select(date, V6Topic, V4)

#Separate the Likert-scale numbers that measure Political Cynicism from the description (characters)
Louelle_ESS <- separate(Louelle_ESS, w1_q10_1, into = c("w1_q10_1", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w1_q10_2, into = c("w1_q10_2", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w1_q10_3, into = c("w1_q10_3", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w1_q10_4, into = c("w1_q10_4", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w2_q7_1, into = c("w2_q7_1", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w2_q7_2, into = c("w2_q7_2", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w2_q7_3, into = c("w2_q7_3", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w2_q7_4, into = c("w2_q7_4", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w3_q11_1, into = c("w3_q11_1", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w3_q11_2, into = c("w3_q11_2", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w3_q11_3, into = c("w3_q11_3", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w3_q11_4, into = c("w3_q11_4", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w4_q13_1, into = c("w4_q13_1", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w4_q13_2, into = c("w4_q13_2", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w4_q13_3, into = c("w4_q13_3", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w4_q13_4, into = c("w4_q13_4", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w1_q49_1, into = c("W1Q491", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w1_q49_2, into = c("W1Q492", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w1_q50_1, into = c("W1Q501", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w1_q50_2, into = c("W1Q502", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w1_q50_6, into = c("W1Q506", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w1_q51_2, into = c("W1Q512", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w2_q44_1, into = c("W2Q441", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w2_q44_2, into = c("W2Q442", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w2_q45_1, into = c("W2Q451", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w2_q45_2, into = c("W2Q452", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w2_q45_6, into = c("W2Q456", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w2_q46_2, into = c("W2Q462", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w3_q43_1, into = c("W3Q431", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w3_q43_2, into = c("W3Q432", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w3_q44_1, into = c("W3Q441", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w3_q44_2, into = c("W3Q442", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w3_q44_6, into = c("W3Q446", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w3_q45_2, into = c("W3Q452", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w4_q47_1, into = c("W4Q471", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w4_q47_2, into = c("W4Q472", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w4_q48_1, into = c("W4Q481", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w4_q48_2, into = c("W4Q482", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w4_q48_6, into = c("W4Q486", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w4_q49_2, into = c("W4Q492", "varvalue"), sep = " ")

# Remove the columns that have the description (character) of the Likert-scale that measures Political Cynicism
Louelle_ESS$varvalue <- NULL

# Change the Likert-scales that measure Political Cynicism from character to numeric
Louelle_ESS$w1_q10_1 <- as.numeric(as.character(Louelle_ESS$w1_q10_1))
Louelle_ESS$w1_q10_2 <- as.numeric(as.character(Louelle_ESS$w1_q10_2))
Louelle_ESS$w1_q10_3 <- as.numeric(as.character(Louelle_ESS$w1_q10_3))
Louelle_ESS$w1_q10_4 <- as.numeric(as.character(Louelle_ESS$w1_q10_4))
Louelle_ESS$w2_q7_1 <- as.numeric(as.character(Louelle_ESS$w2_q7_1))
Louelle_ESS$w2_q7_2 <- as.numeric(as.character(Louelle_ESS$w2_q7_2))
Louelle_ESS$w2_q7_3 <- as.numeric(as.character(Louelle_ESS$w2_q7_3))
Louelle_ESS$w2_q7_4 <- as.numeric(as.character(Louelle_ESS$w2_q7_4))
Louelle_ESS$w3_q11_1 <- as.numeric(as.character(Louelle_ESS$w3_q11_1))
Louelle_ESS$w3_q11_2 <- as.numeric(as.character(Louelle_ESS$w3_q11_2))
Louelle_ESS$w3_q11_3 <- as.numeric(as.character(Louelle_ESS$w3_q11_3))
Louelle_ESS$w3_q11_4 <- as.numeric(as.character(Louelle_ESS$w3_q11_4))
Louelle_ESS$w4_q13_1 <- as.numeric(as.character(Louelle_ESS$w4_q13_1))
Louelle_ESS$w4_q13_2 <- as.numeric(as.character(Louelle_ESS$w4_q13_2))
Louelle_ESS$w4_q13_3 <- as.numeric(as.character(Louelle_ESS$w4_q13_3))
Louelle_ESS$w4_q13_4 <- as.numeric(as.character(Louelle_ESS$w4_q13_4))
Louelle_ESS$W1Q491 <- as.numeric(as.character(Louelle_ESS$W1Q491))
Louelle_ESS$W1Q492 <- as.numeric(as.character(Louelle_ESS$W1Q492))
Louelle_ESS$W1Q501 <- as.numeric(as.character(Louelle_ESS$W1Q501))
Louelle_ESS$W1Q502 <- as.numeric(as.character(Louelle_ESS$W1Q502))
Louelle_ESS$W1Q506 <- as.numeric(as.character(Louelle_ESS$W1Q506))
Louelle_ESS$W1Q512 <- as.numeric(as.character(Louelle_ESS$W1Q512))
Louelle_ESS$W2Q441 <- as.numeric(as.character(Louelle_ESS$W2Q441))
Louelle_ESS$W2Q442 <- as.numeric(as.character(Louelle_ESS$W2Q442))
Louelle_ESS$W2Q451 <- as.numeric(as.character(Louelle_ESS$W2Q451))
Louelle_ESS$W2Q452 <- as.numeric(as.character(Louelle_ESS$W2Q452))
Louelle_ESS$W2Q456 <- as.numeric(as.character(Louelle_ESS$W2Q456))
Louelle_ESS$W2Q462 <- as.numeric(as.character(Louelle_ESS$W2Q462))
Louelle_ESS$W3Q431 <- as.numeric(as.character(Louelle_ESS$W3Q431))
Louelle_ESS$W3Q432 <- as.numeric(as.character(Louelle_ESS$W3Q432))
Louelle_ESS$W3Q441 <- as.numeric(as.character(Louelle_ESS$W3Q441))
Louelle_ESS$W3Q442 <- as.numeric(as.character(Louelle_ESS$W3Q442))
Louelle_ESS$W3Q446 <- as.numeric(as.character(Louelle_ESS$W3Q446))
Louelle_ESS$W3Q452 <- as.numeric(as.character(Louelle_ESS$W3Q452))
Louelle_ESS$W4Q471 <- as.numeric(as.character(Louelle_ESS$W4Q471))
Louelle_ESS$W4Q472 <- as.numeric(as.character(Louelle_ESS$W4Q472))
Louelle_ESS$W4Q481 <- as.numeric(as.character(Louelle_ESS$W4Q481))
Louelle_ESS$W4Q482 <- as.numeric(as.character(Louelle_ESS$W4Q482))
Louelle_ESS$W4Q486 <- as.numeric(as.character(Louelle_ESS$W4Q486))
Louelle_ESS$W4Q492 <- as.numeric(as.character(Louelle_ESS$W4Q492))

# Calculate the average mean of the construct Political Cynisism (by wave)
Louelle_ESS$Mean <- ifelse(Louelle_ESS$Wavevalue == 1, rowMeans(subset(Louelle_ESS, select = c(w1_q10_1,w1_q10_2, w1_q10_3, w1_q10_4)), na.rm = TRUE), ifelse(Louelle_ESS$Wavevalue == 2, rowMeans(subset(Louelle_ESS, select = c(w2_q7_1, w2_q7_2, w2_q7_3, w2_q7_4)), na.rm = TRUE), ifelse(Louelle_ESS$Wavevalue == 3, rowMeans(subset(Louelle_ESS, select = c(w3_q11_1, w3_q11_2, w3_q11_3, w3_q11_4)), na.rm = TRUE), ifelse(Louelle_ESS$Wavevalue == 4, rowMeans(subset(Louelle_ESS, select = c(w4_q13_1, w4_q13_2, w4_q13_3, w4_q13_4)), na.rm = TRUE), NA))))

Louelle_ESS$w1_q10_1 <- NULL
Louelle_ESS$w1_q10_2 <- NULL
Louelle_ESS$w1_q10_3 <- NULL
Louelle_ESS$w1_q10_4 <- NULL
Louelle_ESS$w2_q7_1 <- NULL
Louelle_ESS$w2_q7_2 <- NULL
Louelle_ESS$w2_q7_3 <- NULL
Louelle_ESS$w2_q7_4 <- NULL
Louelle_ESS$w3_q11_1 <- NULL
Louelle_ESS$w3_q11_2 <- NULL
Louelle_ESS$w3_q11_3 <- NULL
Louelle_ESS$w3_q11_4 <- NULL
Louelle_ESS$w4_q13_1 <- NULL
Louelle_ESS$w4_q13_2 <- NULL
Louelle_ESS$w4_q13_3 <- NULL
Louelle_ESS$w4_q13_4 <- NULL

# Filter Content Analysis-data to only "Elections" articles in Dutch media (de Telegraaf, de Volkskrant, NOS Journaal, NRC Handelsblad, nu.nl and RTL Nieuws)
Louelle_CA <- Louelle_CA %>% filter(V6Topic == "Elections") %>% filter(V4 %in% c("de Telegraaf", "de Volkskrant", "NOS Journaal", "NRC Handelsblad", "nu.nl", "RTL Nieuws")) %>% count(date)
Louelle_CA$n <- as.numeric(as.integer(Louelle_CA$n))

# Filter Survey-data so only respondents who are exposed to one of the media outlets (de Telegraaf, de Volkskrant, NOS Journaal, NRC Handelsblad, nu.nl and RTL Nieuws) at least once a week 
Louelle_ESS$sum <- ifelse(Louelle_ESS$Wavevalue == 1,rowSums(subset(Louelle_ESS, select = c(W1Q491, W1Q492, W1Q501, W1Q502, W1Q506)), na.rm = TRUE), ifelse(Louelle_ESS$Wavevalue == 2, rowSums(subset(Louelle_ESS, select = c(W2Q441, W2Q442, W2Q451, W2Q452, W2Q452, W2Q462)), na.rm = TRUE), ifelse(Louelle_ESS$Wavevalue == 3, rowSums(subset(Louelle_ESS, select = c(W3Q431, W3Q432, W3Q441, W3Q442, W3Q452)), na.rm = TRUE), ifelse(Louelle_ESS$Wavevalue == 4, rowSums(subset(Louelle_ESS, select = c(W4Q471, W4Q472, W4Q481, W4Q482, W4Q492)), na.rm = TRUE), NA))))
Louelle_ESS <- Louelle_ESS %>% filter(sum >= 1)

# Merge content analysis data with survey data
Louelle_ALL <- merge(Louelle_ESS, Louelle_CA, by = c("date"), all = TRUE)

# Plot the variables over time
p <- ggplot(data = Louelle_ALL, aes(date))
p <- p + geom_smooth(aes(y = n, color = "Amount of articles about elections"), se = FALSE)
p <- p + geom_point(aes(y = Mean), position = "jitter", color = "sky blue", alpha = 1/8)
p <- p + geom_smooth(aes(y = Mean, color = "Polytical cynicism"), se = FALSE)
p <- p + labs(x = "Date", title = "(Second-Level) Agenda Setting:", subtitle = "The influence of Dutch media coverage about 2014 EU elections on political cynicism", y = "Political cynicism")
p <- p + scale_y_continuous(limits = c(1, 7), breaks = c(1, 2, 3, 4, 5, 6, 7), sec.axis = sec_axis(name = "Amount of articles", ~ . * 21 / 7))
p <- p + theme_minimal(base_size = 11)
p <- p + theme(legend.position = "bottom")
p <- p + scale_colour_manual(name = " ", values = c("deep sky blue 4", "sky blue 2"))
p <- p + annotate("text", x=as.Date("2014-05-22", "%Y-%m-%d"), y=5.5, label= "2014 EU election", size=2.5, angle=19)
p <- p + annotate("text", x=as.Date("2014-03-10", "%Y-%m-%d"), y=6.7, label= "Local elections in EU Countries", size=2.5, angle=19)
p <- p + geom_segment(aes(x = as.Date("2014-05-20", "%Y-%m-%d"), y=4.85, xend = as.Date("2014-05-20", "%Y-%m-%d"), yend = 5.25), size = 0.2, color = "deep sky blue 4", linetype = "dotted")
p <- p + geom_segment(aes(x = as.Date("2014-03-17", "%Y-%m-%d"), y=6.25, xend = as.Date("2014-03-17", "%Y-%m-%d"), yend = 6.7), size = 0.3, color = "deep sky blue 4", linetype = "dotted")
p <- p + geom_segment(aes(x = as.Date("2014-02-28", "%Y-%m-%d"), y=5.8, xend = as.Date("2014-02-28", "%Y-%m-%d"), yend = 6.2), size = 0.2, color = "deep sky blue 4", linetype = "dotted")
p <- p + theme(panel.grid.minor = element_blank())
p
```

With the graph above, the relationship between Dutch media coverage (both newspaper, TV and online) and political cynicism amongst the public is shown. Both the amount of articles about elections and the (average) score on political cynicism (from 1 -totally disagree- to 7 -totally agree-) are plotted over time. 

The graph shows that the amount of Dutch articles obout the 2014 EU Elections does not have a direct influence on political cynicism amongst the public. The average score on political cynicism stays somewhat fixed over time.

When critically assessing the graph, some uncertainty problems arise. First of all, political cynicism has only been measured in the four-wave panel survey. Thus, between the four waves (represented in the graph by the grouped dots) political cynicism is not measured and therefore it cannot be concluded with full confidence that (the score on) political cynicism has not changed over time. Besides, the content and sentiment of the news articles about elections is not taken into account within this analysis and it remains unclear whether the survey-respondets were actually exposed to the media content about elections or not. These two factors might play an important (moderating) role in the influence of media coverage on political cynicism. In future research, these factors should be taken into account.

## Matteo Rinaldi
```{r Matteo Rinaldi, echo = FALSE, message = FALSE, warning = FALSE}
#Creating a new object MAT with the Wavevalue variable, indicating in which Wave the observation was collected for each case.
MAT <- ESSclean %>%
  select(Wavevalue) 
#Using the stripper function in order to treat data about anti-immigration attitudes as numeric and be able to use only the numerical number from the observations (E.g. '1 helemaal mee eens' becomes 1).

stripper <- function(string){ 
  str_extract(string, "\\-*\\d+\\.*\\d*")
}
#Adding columns for the anti-immigration attitudes as umeric and then recode them as 1 when the attitudes is 5 or higher towards a negative attitude.
MAT <- MAT%>%
  mutate(antiimm1 = as.numeric(stripper(w1_q42_1))) %>%
  mutate(antiimm2 = as.numeric(stripper(w1_q42_2))) %>%
  mutate(antiimm3 = as.numeric(stripper(w1_q42_3))) %>%
  mutate(antiimm4 = as.numeric(stripper(w1_q42_4))) %>%
   mutate(antiimm5 = as.numeric(stripper(w2_q39_1 ))) %>%
   mutate(antiimm6 = as.numeric(stripper(w2_q39_2))) %>%
   mutate(antiimm7 = as.numeric(stripper(w2_q39_3))) %>%
  mutate(antiimm8 = as.numeric(stripper(w2_q39_4))) %>%
  mutate(antiimm1 =ifelse(antiimm1 < 4, 1, 0)) %>%
  mutate(antiimm2 =ifelse(antiimm2 < 4, 1, 0)) %>%
  mutate(antiimm3 =ifelse(antiimm3 > 4, 1, 0)) %>%
  mutate(antiimm4 =ifelse(antiimm4 < 4, 1, 0)) %>%
  mutate(antiimm5 =ifelse(antiimm5 < 4, 1, 0)) %>%
  mutate(antiimm6 =ifelse(antiimm6 < 4, 1, 0)) %>%
  mutate(antiimm7 =ifelse(antiimm7 > 4, 1, 0)) %>%
  mutate(antiimm8 =ifelse(antiimm8 < 4, 1, 0))


#Adding the variables for political knowledge to the object MAT, recoding them as 1 (for a correct answer) and 0 (for an uncorrect one)
MAT <- ESSclean %>%
mutate(Plknowl1_1 = ifelse(PolKnowl1 == "Frans Timmermans", 1, 0)) %>%
mutate(Plknowl1_2 = ifelse(PolKnowl2 == "4 jaar", 1, 0)) %>%
mutate(Plknowl1_3 = ifelse(PolKnowl3 == 26 , 1, 0)) %>%
mutate(Plknowl1_4 = ifelse(PolKnowl4 == 28, 1, 0)) %>%
mutate(Plknowl1_5 = ifelse(PolKnowl5 == "Martin Schulz", 1, 0)) 

#Creating variables "PoliticalKnowledge" and "AntiImmigrationLevel" computing the means of the scores from the questions about anti-immigrant attitudes and political knowledge. Political knowledge has already been recoded in order to be relating to the cases by view (PoKnowl1 is displaying values for wave 1, PolKnowl2 for wave 2 etc.)
MAT$PoliticalKnowledge <- rowMeans(subset(MAT, select = c(Plknowl1_1, Plknowl1_2, Plknowl1_3, Plknowl1_4, Plknowl1_5)), na.rm = TRUE)

MAT$AntiImmigrationLevel <- rowMeans(subset(MAT, select = c(antiimm1, antiimm2, antiimm3, antiimm4, antiimm5, antiimm6, antiimm7, antiimm8)), na.rm = TRUE)


#Creating a dataframe with the three variables of interest
MAT2 <-  MAT %>%
  select(AntiImmigrationLevel, PoliticalKnowledge, Wavevalue)

#Installing plotly and uploading plotly and tidyverse
install.packages("plotly")
library(plotly)
library(tidyverse)

#Filtering by the first two waves, since anti-immigrant attitudes were only calculated during the 1st and 2nd wave.
MAT2 <- MAT2 %>%
  filter(Wavevalue == 1 | Wavevalue == 2)

#Creating a plot with the geom_bin
p <- ggplot(data = MAT2, aes(x = PoliticalKnowledge, y = AntiImmigrationLevel)) +
  geom_bin2d(bins =6, color = "white") +
  scale_fill_gradient(low = "#00AFBB", high = "#FC4E07")+
  theme_minimal()  + facet_wrap(~Wavevalue)

#Displaying the plot
p <- ggplotly(p)
p
```

In this graphical representation I am using the data from the survey conducted between December 2013 and May 2014 about the attitudes and intentions of citizens towards the European Union. I decided to analyse the interaction between the political knowledge of the surveyd sample and their attitudes towards immigration. I was expecting this relation to be negative: the more one knows about politics and its complexity, the more should be aware that immigration is a complex process and that immigrants are not to blame for the core of the problem itself. I conducted the analysis by recoding the measurement for political knowledge as a dummy variable (right/wrong, coded as 1/0) and by recoding the variables measuring anti-immigrant attitudes by deciding that cases scoring higher or equal to 5 (on a 1 - 7 Likert scale) had to be considered like having a negative attitude toward immigrants, scoring then with a 1. I then created two new variables which are the mean of these results for each participant. I proceeded displaying how the interaction took place with a visualization with ggplot. Interestingly, it seems like the people knowing average about politics (in the centre of the 2d table) are the ones having both the most extreme and most tolerant attitudes towards immigrants. The situation did not changed with the second wave.



```{r Haylee chunk, ECHO = FALSE}

#First, I will work with the content analysis set. First selecting items of interest, some identifying characteristics (e.g. outlet, ID), along with the EU evaluation items.   
EUCA_set <- ALL_FIXED %>% 
dplyr::select(ID, V2, V4, date, V9, V11, V12, V13) %>% #Columns I need related to EU evaluations in CA
  #I filter to select only items in the three newspapers, which will have had the evaluation coded (these were coded when V9 was "Yes, twice or more")
  filter(V9 == "Yes, twice or more", V4 == "de Telegraaf" | V4 == "de Volkskrant" | V4 == "NRC Handelsblad") %>%
  #Next, create a month factor variable
  mutate(month = month(date, label = TRUE)) %>% 
  #Drop any which are missing
  drop_na(month)%>% 
  #Create columns to indicate articles where the sentiment was evaluated re: EU
  mutate(EU_EVAL = ifelse(V11 =="Not applicable / not mentioned" | V11 == "Mentioned but not evaluated", 0, "EU_EVAL"))%>%
  mutate(EP_EVAL = ifelse(V12 =="Not applicable / not mentioned" | V12 == "Mentioned but not evaluated", 0, "EP_EVAL"))%>%
  mutate(DEM_EVAL = ifelse(V13 =="Not applicable / not mentioned" | V13 == "Mentioned but not evaluated", 0, "DEM_EVAL"))%>%
  #Gather these, and then mutate to create new rows for each article by evaluation type
  gather(EV, value = EVAL, EU_EVAL:DEM_EVAL)%>%
  mutate(EVALS = ifelse(EVAL == "EU_EVAL", V11, ifelse(EVAL == "EP_EVAL", V12, ifelse(EVAL == "DEM_EVAL", V13, NA))))%>%
  #Drop cases which had no evaluation
  na.omit(EVALS)%>%
  #drop old columns
  select(-c(V9, V11, V12, V13, EV))%>%
  #recode evaluations into numeric values
  mutate (EU_EVAL = as.numeric(case_when(EVALS == "Negative" ~ "1",
            EVALS == "Rather negative" ~ "2",
            EVALS == "Balanced/mixed" ~ "3", 
            EVALS == "Rather positive" ~ "4",
            EVALS == "Positive" ~ "5")))%>%
  #recode evaluations scale from 1-5 to 1-7 so that it matches survey scale, in order to compare attitudes present in articles vs readers
  mutate_at(c(8), funs(recode(., '1' = 1, '2' = 2.5, '3' = 4, '4' = 5.5, '5' = 7))) %>% 
  #Calculate the mean evaluation score per article, and compress observations back to one per article
  ddply( .(ID, V4, date, month), summarize, mean_eval = mean(EU_EVAL))%>% 
#By selecting based on ID, V4, date and month, I s retain these columns, whilst calculating the mean EU-evaluation score for each article. In this case, a 1 represents negative, and 7 positive sentiment. Note, I checked this against doing it another way (add_column) to see if it worked correctly, and also checked it against cases in the viewer. 
  ddply( .(month, V4), summarize, mean_NP_month = mean(mean_eval))

#I now have a table of mean EU sentiment by newspaper, by month. Next to work on the Survey data. 

H_EES <- ESSclean %>% 
  #First select relevant variables
  select(RESPNR, date, Wavevalue, w1_q26_1:w1_q27_9, w2_q22_1:w2_q23_9, w3_q28_1:w3_q29_9, w4_q31_1:w4_q32_9)%>% 
 #Next, strip non-numeric characters from each row. In hindsight, this should have been done with parse_number(), which would have required only one line of code. This would have read : 
  #mutate_at(c(4:75), funs(parse_number(.))). However, with little time to return and adjust all of the latter variable names, this code has been retained. If I had more time, after realising this mistake I would have adjusted this. Instead, I use the function stripper which relies on reg ex, combined with as.numeric.
  
#Wave 1 stripping
  mutate(W1B1Q1 = as.numeric(stripper(w1_q26_1))) %>% 
  mutate(W1B1Q2 = as.numeric(stripper(w1_q26_2))) %>%
  mutate(W1B1Q3 = as.numeric(stripper(w1_q26_3))) %>%
  mutate(W1B1Q4 = as.numeric(stripper(w1_q26_4))) %>% 
  mutate(W1B1Q5 = as.numeric(stripper(w1_q26_5))) %>%
  mutate(W1B1Q6 = as.numeric(stripper(w1_q26_6))) %>%
  mutate(W1B1Q7 = as.numeric(stripper(w1_q26_7))) %>%
  mutate(W1B1Q8 = as.numeric(stripper(w1_q26_8))) %>%
  mutate(W1B1Q9 = as.numeric(stripper(w1_q26_9))) %>%
  
  mutate(W1B2Q1 = as.numeric(stripper(w1_q27_1)))%>% 
  mutate(W1B2Q2 = as.numeric(stripper(w1_q27_2))) %>%
  mutate(W1B2Q3 = as.numeric(stripper(w1_q27_3))) %>%
  mutate(W1B2Q4 = as.numeric(stripper(w1_q27_4))) %>% 
  mutate(W1B2Q5 = as.numeric(stripper(w1_q27_5))) %>%
  mutate(W1B2Q6 = as.numeric(stripper(w1_q27_6))) %>%
  mutate(W1B2Q7 = as.numeric(stripper(w1_q27_7))) %>%
  mutate(W1B2Q8 = as.numeric(stripper(w1_q27_8))) %>%
  mutate(W1B2Q9 = as.numeric(stripper(w1_q27_9))) %>%
#Wave 2 questions
  mutate(W2B1Q1 = as.numeric(stripper(w2_q22_1))) %>% 
  mutate(W2B1Q2 = as.numeric(stripper(w2_q22_2))) %>%
  mutate(W2B1Q3 = as.numeric(stripper(w2_q22_3))) %>%
  mutate(W2B1Q4 = as.numeric(stripper(w2_q22_4))) %>% 
  mutate(W2B1Q5 = as.numeric(stripper(w2_q22_5))) %>%
  mutate(W2B1Q6 = as.numeric(stripper(w2_q22_6))) %>%
  mutate(W2B1Q7 = as.numeric(stripper(w2_q22_7))) %>%
  mutate(W2B1Q8 = as.numeric(stripper(w2_q22_8))) %>%
  mutate(W2B1Q9 = as.numeric(stripper(w2_q22_9))) %>%
  
  mutate(W2B2Q1 = as.numeric(stripper(w2_q23_1)))%>% 
  mutate(W2B2Q2 = as.numeric(stripper(w2_q23_2))) %>%
  mutate(W2B2Q3 = as.numeric(stripper(w2_q23_3))) %>%
  mutate(W2B2Q4 = as.numeric(stripper(w2_q23_4))) %>% 
  mutate(W2B2Q5 = as.numeric(stripper(w2_q23_5))) %>%
  mutate(W2B2Q6 = as.numeric(stripper(w2_q23_6))) %>%
  mutate(W2B2Q7 = as.numeric(stripper(w2_q23_7))) %>%
  mutate(W2B2Q8 = as.numeric(stripper(w2_q23_8))) %>%
  mutate(W2B2Q9 = as.numeric(stripper(w2_q23_9))) %>%
#Wave 3
    mutate(W3B1Q1 = as.numeric(stripper(w3_q28_1))) %>% 
  mutate(W3B1Q2 = as.numeric(stripper(w3_q28_2))) %>%
  mutate(W3B1Q3 = as.numeric(stripper(w3_q28_3))) %>%
  mutate(W3B1Q4 = as.numeric(stripper(w3_q28_4))) %>% 
  mutate(W3B1Q5 = as.numeric(stripper(w3_q28_5))) %>%
  mutate(W3B1Q6 = as.numeric(stripper(w3_q28_6))) %>%
  mutate(W3B1Q7 = as.numeric(stripper(w3_q28_7))) %>%
  mutate(W3B1Q8 = as.numeric(stripper(w3_q28_8))) %>%
  mutate(W3B1Q9 = as.numeric(stripper(w3_q28_9))) %>%
  
  mutate(W3B2Q1 = as.numeric(stripper(w3_q29_1)))%>% 
  mutate(W3B2Q2 = as.numeric(stripper(w3_q29_2))) %>%
  mutate(W3B2Q3 = as.numeric(stripper(w3_q29_3))) %>%
  mutate(W3B2Q4 = as.numeric(stripper(w3_q29_4))) %>% 
  mutate(W3B2Q5 = as.numeric(stripper(w3_q29_5))) %>%
  mutate(W3B2Q6 = as.numeric(stripper(w3_q29_6))) %>%
  mutate(W3B2Q7 = as.numeric(stripper(w3_q29_7))) %>%
  mutate(W3B2Q8 = as.numeric(stripper(w3_q29_8))) %>%
  mutate(W3B2Q9 = as.numeric(stripper(w3_q29_9))) %>%
#Wave 4
  mutate(W4B1Q1 = as.numeric(stripper(w4_q31_1))) %>% 
  mutate(W4B1Q2 = as.numeric(stripper(w4_q31_2))) %>%
  mutate(W4B1Q3 = as.numeric(stripper(w4_q31_3))) %>%
  mutate(W4B1Q4 = as.numeric(stripper(w4_q31_4))) %>% 
  mutate(W4B1Q5 = as.numeric(stripper(w4_q31_5))) %>%
  mutate(W4B1Q6 = as.numeric(stripper(w4_q31_6))) %>%
  mutate(W4B1Q7 = as.numeric(stripper(w4_q31_7))) %>%
  mutate(W4B1Q8 = as.numeric(stripper(w4_q31_8))) %>%
  mutate(W4B1Q9 = as.numeric(stripper(w4_q31_9))) %>%
  
  mutate(W4B2Q1 = as.numeric(stripper(w4_q32_1)))%>% 
  mutate(W4B2Q2 = as.numeric(stripper(w4_q32_2))) %>%
  mutate(W4B2Q3 = as.numeric(stripper(w4_q32_3))) %>%
  mutate(W4B2Q4 = as.numeric(stripper(w4_q32_4))) %>% 
  mutate(W4B2Q5 = as.numeric(stripper(w4_q32_5))) %>%
  mutate(W4B2Q6 = as.numeric(stripper(w4_q32_6))) %>%
  mutate(W4B2Q7 = as.numeric(stripper(w4_q32_7))) %>%
  mutate(W4B2Q8 = as.numeric(stripper(w4_q32_8))) %>%
  mutate(W4B2Q9 = as.numeric(stripper(w4_q32_9))) %>%
  select(RESPNR, date, Wavevalue, W1B1Q1:W4B2Q9) %>%

  #In block 2 of the EU attitudes variables, items 5 through 8 are reverse coded. Therefore, I used the below command to check their column number, and recode these variables.
#which(names(H_EES)%in%c("W1B2Q5", "W1B2Q8", "W2B2Q5", "W2B2Q8", "W3B2Q5", "W3B2Q8", "W4B2Q5", "W4B2Q8"))
mutate_at(c(17:20, 35:38, 53:56, 71:74), funs(recode(., `1` = 7, `2` = 6, `3` = 5, `4` = 4, `5` = 3, `6` = 2, `7` = 1)))%>%
#Based on the wave values for each respondent, I assign their score for each item in block 1 and block 2 of EU attitudes questions, otherwise NA.
#Block 1 questions
  mutate(B1Q1 = ifelse(Wavevalue == 1, W1B1Q1, ifelse(ESSclean$Wavevalue == 2, W2B1Q1, ifelse(Wavevalue == 3, W3B1Q1, ifelse(ESSclean$Wavevalue == 4, W4B1Q1, NA))))) %>%
  mutate(B1Q2 = ifelse(Wavevalue == 1, W1B1Q2, ifelse(ESSclean$Wavevalue == 2, W2B1Q2, ifelse(Wavevalue == 3, W3B1Q2, ifelse(ESSclean$Wavevalue == 4, W4B1Q2, NA))))) %>%
  mutate(B1Q3 = ifelse(Wavevalue == 1, W1B1Q3, ifelse(ESSclean$Wavevalue == 2, W2B1Q3, ifelse(Wavevalue == 3, W3B1Q3, ifelse(ESSclean$Wavevalue == 4, W4B1Q3, NA))))) %>%
  mutate(B1Q4 = ifelse(Wavevalue == 1, W1B1Q4, ifelse(ESSclean$Wavevalue == 2, W2B1Q4, ifelse(Wavevalue == 3, W3B1Q4, ifelse(ESSclean$Wavevalue == 4, W4B1Q4, NA))))) %>%
  mutate(B1Q5 = ifelse(Wavevalue == 1, W1B1Q5, ifelse(ESSclean$Wavevalue == 2, W2B1Q5, ifelse(Wavevalue == 3, W3B1Q5, ifelse(ESSclean$Wavevalue == 4, W4B1Q5, NA))))) %>%
  mutate(B1Q6 = ifelse(Wavevalue == 1, W1B1Q6, ifelse(ESSclean$Wavevalue == 2, W2B1Q6, ifelse(Wavevalue == 3, W3B1Q6, ifelse(ESSclean$Wavevalue == 4, W4B1Q6, NA))))) %>%
  mutate(B1Q7 = ifelse(Wavevalue == 1, W1B1Q7, ifelse(ESSclean$Wavevalue == 2, W2B1Q7, ifelse(Wavevalue == 3, W3B1Q7, ifelse(ESSclean$Wavevalue == 4, W4B1Q7, NA))))) %>%
  mutate(B1Q8 = ifelse(Wavevalue == 1, W1B1Q8, ifelse(ESSclean$Wavevalue == 2, W2B1Q8, ifelse(Wavevalue == 3, W3B1Q8, ifelse(ESSclean$Wavevalue == 4, W4B1Q8, NA))))) %>% 
mutate(B1Q9 = ifelse(Wavevalue == 1, W1B1Q9, ifelse(ESSclean$Wavevalue == 2, W2B1Q9, ifelse(Wavevalue == 3, W3B1Q9, ifelse(ESSclean$Wavevalue == 4, W4B1Q9, NA))))) %>%
#Block 2 questions
    mutate(B2Q1 = ifelse(Wavevalue == 1, W1B2Q1, ifelse(ESSclean$Wavevalue == 2, W2B2Q1, ifelse(Wavevalue == 3, W3B2Q1, ifelse(ESSclean$Wavevalue == 4, W4B2Q1, NA))))) %>%
  mutate(B2Q2 = ifelse(Wavevalue == 1, W1B2Q2, ifelse(ESSclean$Wavevalue == 2, W2B2Q2, ifelse(Wavevalue == 3, W3B2Q2, ifelse(ESSclean$Wavevalue == 4, W4B2Q2, NA))))) %>%
  mutate(B2Q3 = ifelse(Wavevalue == 1, W1B2Q3, ifelse(ESSclean$Wavevalue == 2, W2B2Q3, ifelse(Wavevalue == 3, W3B2Q3, ifelse(ESSclean$Wavevalue == 4, W4B2Q3, NA))))) %>%
  mutate(B2Q4 = ifelse(Wavevalue == 1, W1B2Q4, ifelse(ESSclean$Wavevalue == 2, W2B2Q4, ifelse(Wavevalue == 3, W3B2Q4, ifelse(ESSclean$Wavevalue == 4, W4B2Q4, NA))))) %>%
  mutate(B2Q5 = ifelse(Wavevalue == 1, W1B2Q5, ifelse(ESSclean$Wavevalue == 2, W2B2Q5, ifelse(Wavevalue == 3, W3B2Q5, ifelse(ESSclean$Wavevalue == 4, W4B2Q5, NA))))) %>%
  mutate(B2Q6 = ifelse(Wavevalue == 1, W1B2Q6, ifelse(ESSclean$Wavevalue == 2, W2B2Q6, ifelse(Wavevalue == 3, W3B2Q6, ifelse(ESSclean$Wavevalue == 4, W4B2Q6, NA))))) %>%
  mutate(B2Q7 = ifelse(Wavevalue == 1, W1B2Q7, ifelse(ESSclean$Wavevalue == 2, W2B2Q7, ifelse(Wavevalue == 3, W3B2Q7, ifelse(ESSclean$Wavevalue == 4, W4B2Q7, NA))))) %>%
  mutate(B2Q8 = ifelse(Wavevalue == 1, W1B2Q8, ifelse(ESSclean$Wavevalue == 2, W2B2Q8, ifelse(Wavevalue == 3, W3B2Q8, ifelse(ESSclean$Wavevalue == 4, W4B2Q8, NA))))) %>% 
mutate(B2Q9 = ifelse(Wavevalue == 1, W1B2Q9, ifelse(ESSclean$Wavevalue == 2, W2B2Q9, ifelse(Wavevalue == 3, W3B2Q9, ifelse(ESSclean$Wavevalue == 4, W4B2Q9, NA))))) %>%
  #Drop the old columns
  select(-c(W1B1Q1:W4B2Q9))%>%
  #Calculate mean EU attitudes for each observation - i.e. by respondent, by wave
  mutate(wave_mean = rowMeans(subset(., select = c(B1Q1:B2Q9), na.rm = TRUE)))%>%
  #create month variable
  mutate(month = month(date, label = TRUE)) %>%  #Create month column 
  #drop old columns
  select(-c(B1Q1:B2Q9)) 
#This table contains the respondent ID, date of interview, wave number, mean score (per wave, per respondent), and month.

#The next step is to establish which respondents read which paper, and when.

READERS1 <- ESSclean %>% #First select relevant variables
  select (RESPNR, date, Wavevalue, w1_q50_1:w1_q50_10, w2_q45_1:w2_q45_10, w3_q44_1:w3_q44_10, w4_q48_1:w4_q48_10)%>%
  #Remove non-numeric characters from items asking how many days per week they read each outlet. NOTE: This is the function I should have used above instead of the stripper function I created.
  mutate_at(c(4:43), funs(parse_number(.))) %>% 
  #Create month variable
  mutate(month = month(date, label = TRUE))%>%
  #Identify which readers read which paper, in which wave. I selected newspaper readers based on their reading habits: If they read the paper of concern 5+ days per week, and reported that they read all other options less than 3 days per week.
  mutate(PAPER = case_when(Wavevalue == 1 & w1_q50_1 >= 5 & w1_q50_2:w1_q50_10 < 3 ~ 1,
         Wavevalue == 1 & w1_q50_2 >= 5 & w1_q50_1 < 3 & w1_q50_3: w1_q50_10 < 3 ~ 2, 
         Wavevalue == 1 & w1_q50_6 >= 5 & w1_q50_1:w1_q50_5 < 3 & w1_q50_7: w1_q50_10 < 3 ~ 3,
         Wavevalue == 2 & w2_q45_1 >= 5 & w2_q45_2:w2_q45_10 < 3 ~ 1,
         Wavevalue == 2 & w2_q45_2 >= 5 & w2_q45_1 < 3 & w2_q45_3: w2_q45_10 < 3 ~ 2,
         Wavevalue == 2 & w2_q45_6 >= 5 & w2_q45_1:w2_q45_5 < 3 & w2_q45_7: w2_q45_10 < 3 ~ 3,
         Wavevalue == 3 & w3_q44_1 >= 5 & w3_q44_2:w3_q44_10 < 3 ~ 1,
         Wavevalue == 3 & w3_q44_2 >= 5 & w3_q44_1 < 3 & w3_q44_3: w3_q44_10 < 3 ~ 2,
         Wavevalue == 3 & w3_q44_6 >= 5 & w3_q44_1:w3_q44_5 < 3 & w3_q44_7: w3_q44_10 < 3 ~ 3,
         Wavevalue == 4 & w4_q48_1 >= 5 & w4_q48_2:w4_q48_10 < 3 ~ 1,
         Wavevalue == 4 & w4_q48_2 >= 5 & w4_q48_1 < 3 & w4_q48_3: w4_q48_10 < 3 ~ 2,
         Wavevalue == 4 & w4_q48_6 >= 5 & w4_q48_1:w4_q48_5 < 3 & w4_q48_7: w4_q48_10 < 3 ~ 3,
         TRUE ~ NA_real_)) %>%
  #Keep relevant columns.
  select(RESPNR, date, Wavevalue, PAPER)%>%
  #Drop respondents who did not meet the conditions to be deemed a reader of a given newspaper.
  na.omit(PAPER)%>%
  #Left join with the readers attitudes table 
  left_join(H_EES)%>%
  #Recode outlet names so they're in line with the content analysis names.
  mutate_at(c(4), funs(recode(., '1' = "de Telegraaf", '2' = "NRC Handelsblad", '3' = "de Volkskrant"))) 
# I now have a table with a case for each respondent and wave (where applicable), the date, the outlet they're a reader of, their mean score for that wave, and the month. 

# Using the table above, I need to create another, from which I will use the mean scores per respondent in the jitter geom of the plot. I'm not able to pipe this all the way through as I need two different tables from which to pull variables to plot, to show the individual respondents, and the means of the respondents/newspapers all on the same plot.

READERS2 <- READERS1%>%
  ddply( .(PAPER, month, wave_mean, date), summarize, mean_RESP_month = mean(wave_mean))%>% 
  left_join(EUCA_set, by = c("PAPER" = "V4", "month" = "month"))%>%
  #Select months which I have data for, name the levels in correct order
  mutate(month2 = factor(month, levels = c("Dec", "Mar", "Apr", "May", "Jun")))%>% 
  dplyr::filter(month2 != "Dec", month2 != "Jun") #Drop cases with the months Dec and Jun, the gap in observations between Dec-March is too large, and June had only a few cases per paper. 

#Using READERS1, I will finalise the data and then plot using ggplot. This will be stored in the dataobject "READERS", and subsequently put into ggplotly()

READERS <- READERS1 %>% 
  ddply( .(PAPER, month), summarize, mean_RESP_month = mean(wave_mean))%>% #First calc means for respondents each month, and compress the table based on paper and month.
  left_join(EUCA_set, by = c("PAPER" = "V4", "month" = "month"))%>% #Join this to the content analysis table, which is already structured by paper, by month. 
  mutate(month2 = factor(month, levels = c("Dec", "Mar", "Apr", "May", "Jun")))%>% #Create month2 factor, selecting months with data, and correctly order them. Below, drop Dec/June observations. 
  dplyr::filter(month2 != "Dec", month2 != "Jun")%>% 
  ggplot()+ 
  #Plot the graph, first a geom_jitter layer with light coloured points for individual respondents EU attitudes each month. Also note: The 'text' field is included for the hover text in the eventual ggplotly output.
  geom_jitter(data = READERS2, width = .2, show.legend = TRUE, mapping = aes(x = month2, y = wave_mean, colour = PAPER, alpha = .05, text = paste("</br> Newspaper: ", PAPER, "</br> Inidividuals attitude: ", round(wave_mean, digits = 2), "</br> Month:", month2, "</br> Month:", date)))+
  #Next plot points for each newspapers' readers (overall) average attitudes by month
   geom_point(show.legend = FALSE, mapping = aes(x = month2, y = mean_RESP_month, colour = PAPER, group = PAPER, text = paste("</br> Newspaper: ", PAPER, "</br> Readers average EU attitudes: ", round(mean_RESP_month, digits = 2))))+
  #Add a line for the points, to show their relationship
   geom_line(show.legend = FALSE, size = 1, mapping = aes(x = month2, y = mean_RESP_month, colour = PAPER, group = PAPER, linetype = "Readers"))+
  #Plot points for the EU attitudes/sentiment present within newspaper articles on average, by month
  geom_point(show.legend = FALSE, mapping = aes(x = month2, y = mean_NP_month, colour = PAPER,  group = PAPER, text = paste("</br> Newspaper: ", PAPER, "</br> Newspapers average EU attitudes: ", round(mean_NP_month, digits = 2))))+
  #Add a line to show their relationship
    geom_line(show.legend = FALSE, size = 1, mapping = aes(x = month2, y = mean_NP_month, colour = PAPER, group = PAPER, linetype = "Newspapers"))+
  #Labels for the x axis
 scale_x_discrete(name = FALSE, labels = c("March 2014", "April 2014", "May 2014"))+ 
  #Labels for Y - decision made to name '6' as it shows direction of attitudes scale, '7' was not possible to name as above max. Rather than assigning numeric values, these anchors are informative enough and require little further interpretation from the reader as their order shows the direction of scores.
  scale_y_continuous(name = FALSE, breaks = c(1, 3.5, 6), labels = c("Anti-EU  ", "Neutral", "Pro-EU"))+
  #Differentiate between Newspapers and Readers attitudes lines by selecting different linetypes
    scale_linetype_manual(values=c(Newspapers = "dashed", Readers = "solid"))+
  #add a title
  labs(title = "EU attitudes in the press and of their readers")+
  theme(plot.title = element_text(hjust = 0.5, size = 12))+
  #Theme, and colours
  theme_bw(base_size = 14) + scale_colour_hc()

#Finally, use the ggplotly() function for the final, interactive graph:
ggplotly(READERS, tooltip = c("text", width = 1200, height = 900)) %>% #Select to use the 'text' in the aes settings of above ggplot geoms as the hover text in ggplotly output. 
  layout(showlegend = FALSE) #Hide legend - not optimal, however ggplotly known issue with legend display based on ggplots.
  

```
