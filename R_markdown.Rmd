---
title: 'European Election Campaign Study 2014'
author: Katerin Kunfermann (), Haylee Kelsall (11665424), Louelle Pesurnaij (10750886), Matteo Rinaldi ()
date: "31 January 2019"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


#@@Jobs before handing in: 
#Check code is actually tide for the group part. Is it as concise as possible? e.g. replace nl1a, nl1b, nl1c with nl1a:nl1c. 
#Someone needs to go through CA code, and check 'ID' is in everything. Unforutnately V2 was not a unique ID but instead unique only to coders GAH
#Check there is enough detail given in tiying explanations, including e.g. 'viewed it using head(x) and checked compared to...'
#Check entire thing ACTUALLY runs
#Check spelling, cntrl+f search for @ signs notes to be done/removed
#WRITE TEXT INTRODUCING THE OVERALL INFOGRAPHIC... Somehow
#Do all visualisation fit together somehow in terms of style?
#All names on the document? Title? Date? Etc. 
#How does the text knit? 
#Set code chunks to echo = False
#@@More to be added to list of shit to do... 

##CONTENT ANALYSIS SET STILL NEEDS TO BE CHECKED FOR OTHER RULES OF TIDYING!!!!!!!!


```



```{r import survey data and access packages}
library(tidyverse) #access tidyverse
library(lubridate) #lubridate (@@remove this if we don't actually use it in the end)
#@@add other additional packages needed here - e.g. for interactive plots etc. 

CA <- read_csv("Dataset MCA EPE 2014 NL FINAL.csv") #Read content analysis file, store under CA
# @ later remove this so also contetn analysis is imported here

ESS <- read_csv("All waves GENERAL.csv") # read survey file, store under ESS (Election Study Survey)

#Tidying the data set. Step ONE: Seperate respondent fixed characteristics, with help of code book.
#Examples of these: demographics, big 5 personality traits etc. Here the RESPONDENT is the unit. 
#We also want to include here a column for the waves which the participant was in, we only have the 'GENERAL' panel data so not neccessary to create additional columns for other panels. 

ESS %>%
  summarise(n_RESPS = n_distinct(RESPNR)) #Check all respondent IDs unique. Respondent ID will be #used as our primary key in this table.
# @ wave weighting should probabbly be in the wave'd variables seeing as they apply to each wave, fix this later @H

#tidy columns respondent ID and Waves
ESS %>% count(WAVES) #First count the number of respondents participating in each level of 'WAVES'.

#Wave 1
ESS$wave1 <- ifelse(ESS$WAVES == "All waves", 1, ifelse(ESS$WAVES == "Only wave 1", 1, ifelse(ESS$WAVES == "Wave 1 and 2", 1, ifelse(ESS$WAVES == "Wave 1, 2 and 3", 1, 0)))) 
#Create new column called "wave1" in ESS, assign the value 1 = YES 0 = NO. (Note all participants were in at least wave1) 

#Wave 2
ESS$wave2 <- ifelse(ESS$WAVES == "All waves", 1, ifelse(ESS$WAVES == "Wave 1 and 2", 1, ifelse(ESS$WAVES == "Wave 1, 2 and 3", 1, 0))) #Create new column called "wave2" in ESS, assign the value 1 = YES if respondent participated in wave 2, 0 = NO. 

#Wave 3
ESS$wave3 <- ifelse(ESS$WAVES == "All waves", 1, ifelse(ESS$WAVES == "Wave 1, 2 and 3", 1, 0)) 
#Create new column called "wave3" in ESS, assign the value 1 = YES if respondent participated in wave 3, 0 = NO. 

#Wave 4
ESS$wave4 <- ifelse(ESS$WAVES == "All waves", 1, 0) #Create new column called "wave4" in ESS, assign the value 1 = YES if respondent participated in wave 4, 0 = NO.

RESP_DEMOG <- ESS %>%
  group_by(INTNR, RESPNR,	SAMPLE,	WAVES,	GEWICHTA1_w1,	GEWICHTA1_w2,	GEWICHTA1_w3,	GEWICHTA1_w4,	GSL,	LFT,	OPLA,	NIELSENCBS,	GEZINSGROOTTE,	POL2012, w1_q5_1, w1_q5_2, w1_q5_3, w1_q5_4, w1_q17_1, w1_q17_2, w1_q17_3, w1_q17_4, w1_q23, w1_q24_1, w1_q24_2, w1_q24_3, w1_q29, w1_q30_1,w1_q30_2,	w1_q30_3,	w1_q30_4,	w1_q30_5,	w1_q30_6,	w1_q30_7,	w1_q30_8,	w1_q30_9,	w1_q30_10,	w1_q30_11, w1_q31_1,	w1_q31_2,	w1_q31_3,	w1_q31_4,	w1_q31_5,	w1_q31_6,	w1_q31_7,	w1_q31_8,	w1_q31_9,	w1_q32_1,	w1_q32_2,	w1_q32_3,	w1_q32_4, w1_q57_1,	w1_q57_2,	w1_q57_3,	w1_q57_4,	w1_q57_5,	w1_q57_6,	w1_q57_7,	w1_q57_8,	w1_q58_1,	w1_q58_2,	w1_q58_3,	w1_q58_4,	w1_q58_5,	w1_q58_6,	w1_q58_7,	w1_q58_8,	w1_q58_9,	w1_q58_10,	w1_q59,	w1_q60,	w1_q61,	w1_q62,	w1_q64,	w1_q65,	w1_q66,	w1_q67,	w1_q68,	w1_q68_YES, w2_q25,	w2_q26_1,	w2_q26_2,	w2_q26_3,	w2_q26_4,	w2_q26_5,	w2_q26_6,	w2_q26_7,	w2_q26_8,	w2_q26_9,	w2_q26_10,	w2_q26_11,	w2_q27_1,	w2_q27_2,	w2_q27_3,	w2_q27_4,	w2_q27_5,	w2_q27_6,	w2_q27_7,	w2_q27_8,	w2_q27_9,	w2_q28_1,	w2_q28_2,	w2_q28_3,	w2_q28_4,	w2_q28_5,	w2_q28_6,	w2_q28_7,	w2_q28_8,	w2_q28_9,	w2_q28_10,	w2_q28_11,	w2_q29,	w2_q30,	w2_q30_OTHER_LOCAL,	w2_q30_OTHER,	w2_q31,	w2_q32_1,	w2_q32_2,	w2_q32_3,	w2_q32_4,	w2_q32_5,	w2_q32_OTHER,	w2_q33_1,	w2_q33_2,	w2_q33_3,	w2_q33_4,	w2_q33_5,	w2_q33_6,	w2_q33_7,	w2_q33_8,	w2_q33_9,	w2_q33_10,	w2_q33_11,	w2_q33_12,	w2_q33_13,	w2_q33_14,	w2_q33_OTHER_LOCAL,	w2_q33_OTHER,	w2_q50_1,	w2_q50_2,	w2_q50_3,	w2_q50_4,	w2_q50_5,	w2_q50_6,	w2_q51,	w2_q52_1,	w2_q52_2,	w2_q52_3,	w2_q52_4,	w2_q52_5,	w2_q53_1,	w2_q53_2,	w2_q54,	w2_q55,	w2_q56_1,	w2_q56_2,	w2_q56_3,	w2_q56_4, w2_q61_1,	w2_q61_2,	w2_q62_CONDITION1,	w2_q62_CONDITION2, w2_q63,	w2_q65, w3_q49TRUE_1,	w3_q49TRUE_2,	w3_q49TRUE_3,	w3_q49TRUE_4,	w3_q49TRUE_5,	w3_q49TRUE_6,	w3_q49TRUE_7,	w3_q49_1,	w3_q49_2,	w3_q49_3,	w3_q49_4,	w3_q49_5,	w3_q49_6,	w3_q49_7, w3_q56_CONDITION1_1,	w3_q56_CONDITION1_2,	w3_q56_CONDITION1_3,	w3_q56_CONDITION1_4,	w3_q56_CONDITION2_1,	w3_q56_CONDITION2_2,	w3_q56_CONDITION2_3,	w3_q56_CONDITION2_4,	w3_q56_TIMESTAMP, w3_q59_1,	w3_q59_2,	w3_q59_3,	w3_q60_1,	w3_q60_2,	w3_q60_3,	w3_q60_4, w4_q7,	w4_q8,	w4_q9, w4_q27, w4_q41_1,	w4_q41_2,	w4_q41_3,	w4_q41_4,	w4_q41_5,	w4_q41_6,	w4_q41_7,	w4_q41_8,	w4_q41_9,	w4_q41_10,	w4_q41_11, w4_q41_12,  w4_q43_1,	w4_q43_2,	w4_q43_3,	w4_q43_4,	w4_q43_5,	w4_q43_6,	w4_q43_7,	w4_q43_8,	w4_q43_9,	w4_q43_10,	w4_q43_11,	w4_q43_12, w4_q51_1,	w4_q51_2,	w4_q51_3,	w4_q51_4,	w4_q51_5,	w4_q51_OTHER,	w4_q52_1,	w4_q52_2,	w4_q52_3,	w4_q52_4,	w4_q52_5,	w4_q52_6,	w4_q52_7,	w4_q52_8,	w4_q52_9,	w4_q52_10,	w4_q52_11,	w4_q52_12,	w4_q52_13,	w4_q52_OTHER, w4_q57, w4_q62_1,	w4_q62_2,	w4_q62_3,	w4_q62_4,	w4_q62_5,	w4_q62_6,	w4_q62_7) %>%
summarise()
RESP_DEMOG #Now we have a table with all fixed characteristics of respondents. We still need to check every single variable that it meets rules of tidy data even thouh now at least 'each unit has its own table' is PARTLY fulfilled with this table @@

#@@ NOTE!!! SOME VARIABLES ABOVE HAVE BEEN RECODED already into standard variable names already such as w1_q61 is actualy OPLA (opleiding) 

#Change W3_Q56
RESP_DEMOG_test <- RESP_DEMOG %>% group_by(RESPNR, w3_q56_CONDITION1_1, w3_q56_CONDITION1_2, w3_q56_CONDITION1_3, w3_q56_CONDITION1_4, w3_q56_CONDITION2_1, w3_q56_CONDITION2_2, w3_q56_CONDITION2_3, w3_q56_CONDITION2_4) %>% select(RESPNR, w3_q56_CONDITION1_1, w3_q56_CONDITION1_2, w3_q56_CONDITION1_3, w3_q56_CONDITION1_4, w3_q56_CONDITION2_1, w3_q56_CONDITION2_2, w3_q56_CONDITION2_3, w3_q56_CONDITION2_4)

#Splitting the Experiment-data
RESP_DEMOG$W3_Q56_CONDITION <- ifelse(!is.na(RESP_DEMOG$w3_q56_CONDITION1_1), 1, ifelse(!is.na(RESP_DEMOG$w3_q56_CONDITION1_2), 1, ifelse(!is.na(RESP_DEMOG$w3_q56_CONDITION1_3), 1, ifelse(!is.na(RESP_DEMOG$w3_q56_CONDITION1_4), 1, ifelse(!is.na(RESP_DEMOG$w3_q56_CONDITION2_1), 2, ifelse(!is.na(RESP_DEMOG$w3_q56_CONDITION2_2), 2, ifelse(!is.na(RESP_DEMOG$w3_q56_CONDITION2_3), 2, ifelse(!is.na(RESP_DEMOG$w3_q56_CONDITION2_4), 2, NA)))))))) 

```


```{r Spread the waveeeeees}
#select relevant variables for all waves
ESSclean <- select(ESS, -c(INTNR, SAMPLE,	GEWICHTA1_w1,	GEWICHTA1_w2,	GEWICHTA1_w3,	GEWICHTA1_w4,	GSL,	LFT,	OPLA,	NIELSENCBS,	GEZINSGROOTTE,	POL2012, w1_q5_1, w1_q5_2, w1_q5_3, w1_q5_4, w1_q17_1, w1_q17_2, w1_q17_3, w1_q17_4, w1_q23, w1_q24_1, w1_q24_2, w1_q24_3, w1_q29, w1_q30_1,w1_q30_2,	w1_q30_3,	w1_q30_4,	w1_q30_5,	w1_q30_6,	w1_q30_7,	w1_q30_8,	w1_q30_9,	w1_q30_10,	w1_q30_11, w1_q31_1,	w1_q31_2,	w1_q31_3,	w1_q31_4,	w1_q31_5,	w1_q31_6,	w1_q31_7,	w1_q31_8,	w1_q31_9,	w1_q32_1,	w1_q32_2,	w1_q32_3,	w1_q32_4, w1_q57_1,	w1_q57_2,	w1_q57_3,	w1_q57_4,	w1_q57_5,	w1_q57_6,	w1_q57_7,	w1_q57_8,	w1_q58_1,	w1_q58_2,	w1_q58_3,	w1_q58_4,	w1_q58_5,	w1_q58_6,	w1_q58_7,	w1_q58_8,	w1_q58_9,	w1_q58_10,	w1_q59,	w1_q60,	w1_q61,	w1_q62,	w1_q64,	w1_q65,	w1_q66,	w1_q67,	w1_q68,	w1_q68_YES, w2_q25,	w2_q26_1,	w2_q26_2,	w2_q26_3,	w2_q26_4,	w2_q26_5,	w2_q26_6,	w2_q26_7,	w2_q26_8,	w2_q26_9,	w2_q26_10,	w2_q26_11,	w2_q27_1,	w2_q27_2,	w2_q27_3,	w2_q27_4,	w2_q27_5,	w2_q27_6,	w2_q27_7,	w2_q27_8,	w2_q27_9,	w2_q28_1,	w2_q28_2,	w2_q28_3,	w2_q28_4,	w2_q28_5,	w2_q28_6,	w2_q28_7,	w2_q28_8,	w2_q28_9,	w2_q28_10,	w2_q28_11,	w2_q29,	w2_q30,	w2_q30_OTHER_LOCAL,	w2_q30_OTHER,	w2_q31,	w2_q32_1,	w2_q32_2,	w2_q32_3,	w2_q32_4,	w2_q32_5,	w2_q32_OTHER,	w2_q33_1,	w2_q33_2,	w2_q33_3,	w2_q33_4,	w2_q33_5,	w2_q33_6,	w2_q33_7,	w2_q33_8,	w2_q33_9,	w2_q33_10,	w2_q33_11,	w2_q33_12,	w2_q33_13,	w2_q33_14,	w2_q33_OTHER_LOCAL,	w2_q33_OTHER,	w2_q50_1,	w2_q50_2,	w2_q50_3,	w2_q50_4,	w2_q50_5,	w2_q50_6,	w2_q51,	w2_q52_1,	w2_q52_2,	w2_q52_3,	w2_q52_4,	w2_q52_5,	w2_q53_1,	w2_q53_2,	w2_q54,	w2_q55,	w2_q56_1,	w2_q56_2,	w2_q56_3,	w2_q56_4, w2_q61_1,	w2_q61_2,	w2_q62_CONDITION1,	w2_q62_CONDITION2, w2_q63,	w2_q65, w3_q49TRUE_1,	w3_q49TRUE_2,	w3_q49TRUE_3,	w3_q49TRUE_4,	w3_q49TRUE_5,	w3_q49TRUE_6,	w3_q49TRUE_7,	w3_q49_1,	w3_q49_2,	w3_q49_3,	w3_q49_4,	w3_q49_5,	w3_q49_6,	w3_q49_7, w3_q56_CONDITION1_1,	w3_q56_CONDITION1_2,	w3_q56_CONDITION1_3,	w3_q56_CONDITION1_4,	w3_q56_CONDITION2_1,	w3_q56_CONDITION2_2,	w3_q56_CONDITION2_3,	w3_q56_CONDITION2_4,	w3_q56_TIMESTAMP, w3_q59_1,	w3_q59_2,	w3_q59_3,	w3_q60_1,	w3_q60_2,	w3_q60_3,	w3_q60_4, w4_q7,	w4_q8,	w4_q9, w4_q27, w4_q41_1,	w4_q41_2,	w4_q41_3,	w4_q41_4,	w4_q41_5,	w4_q41_6,	w4_q41_7,	w4_q41_8,	w4_q41_9,	w4_q41_10,	w4_q41_11, w4_q41_12,  w4_q43_1,	w4_q43_2,	w4_q43_3,	w4_q43_4,	w4_q43_5,	w4_q43_6,	w4_q43_7,	w4_q43_8,	w4_q43_9,	w4_q43_10,	w4_q43_11,	w4_q43_12, w4_q51_1,	w4_q51_2,	w4_q51_3,	w4_q51_4,	w4_q51_5,	w4_q51_OTHER,	w4_q52_1,	w4_q52_2,	w4_q52_3,	w4_q52_4,	w4_q52_5,	w4_q52_6,	w4_q52_7,	w4_q52_8,	w4_q52_9,	w4_q52_10,	w4_q52_11,	w4_q52_12,	w4_q52_13,	w4_q52_OTHER, w4_q57, w4_q62_1,	w4_q62_2,	w4_q62_3,	w4_q62_4,	w4_q62_5,	w4_q62_6,	w4_q62_7, wave1, wave2, wave3, wave4))

#Change values 1 (=TRUE) to 2 (=participates in wave 2)
#Wave 1
ESSclean$wave1 <- ifelse(ESS$wave1 == 1, 1, NA)
#Wave 2
ESSclean$wave2 <- ifelse(ESS$wave2 == 1, 2, NA)
#Wave 3
ESSclean$wave3 <- ifelse(ESS$wave3 == 1, 3, NA)
#Wave 4
ESSclean$wave4 <- ifelse(ESS$wave4 == 1, 4, NA)

#Create one out of Wave 1, 2, 3, 4
ESSclean <- ESSclean %>% gather(Wave, Wavevalue, wave1:wave4, na.rm = TRUE, convert = FALSE, factor_key = FALSE)



#remove WAVES and Wave columns
ESSclean$Wave <- NULL

# Clean up date-variables
ESSclean$date <- ifelse(ESSclean$Wavevalue == 1, ESSclean$w1_DATUM, ifelse(ESSclean$Wavevalue == 2, ESSclean$w2_DATUM, ifelse(ESSclean$Wavevalue == 3, ESSclean$w3_DATUM, ifelse(ESSclean$Wavevalue == 4, ESSclean$w4_DATUM, NA))))

# Change date-variable from character to actual date
ESSclean <- transform(ESSclean, date = as.Date(as.character(date), "%Y%m%d"))
```

```{r - CA tidying chunk}

library(lubridate)

#First parse date in original object so all latter tables will already have a 'date' column. day = V3a, month = V3b, year = V3c.
CA$date <- with(CA, dmy(sprintf('%02d%02d%02d', V3a, V3b, V3c))) #Checked in console!
#Also need to add unique id number to each item
CA$ID <- seq.int(nrow(CA))

CA$ID

#Creating table for fixed characteristics relevant to all, i.e. items asked to everything. Checked using console. 
ALL_FIXED <- CA %>% 
  select(ID, V1,	V2,	V3a,	V3b,	V3c, date,	V4,	V5, V6,	V6_cleaned, NL1a : NL1f, V7, V8a, V8b, V9,V11, V12, V13, V14, V15a_TEXT : V15f_TEXT, V15_a_cleaned : V15_f_cleaned,  V16a : V16f, NL7a : NL7e, NL24, NL25, NL26, NL27, NL28a, NL28b, NL29a : NL29g, NL30, NL31, NL32a : NL32g, NL33) #Include V's asked for all

#pull apart column V6_cleaned into two columns by splitting at the ":" 
ALL_FIXED <- separate(ALL_FIXED, V6_cleaned, into = c("V6Topic", "V6Topicdescription"), sep = ":")

#Creating Newspaper fixed characteristics table. Note: nu.nl is included as a newspaper, because it is treated as one in the codebook. Keeping V4 as article ID for primary key, also keeping V4 (outlet) as may be useful also. In addition, note that the belgium outlets are included as they're treated as newspapers. These
#need to probably be removed if neccessary during later analysis!
CA_FIXED_NP <- CA %>%
  filter(V4 != "NOS Journaal" & V4 != "RTL Nieuws")%>% #Exclude (filter out) the two TV channels
  select(ID, V2,	V4, NP1,	NP2,	NP3,	NP4,	NP5,	NP6,	NP7) 

#@@This should be edited if we claim PVV+50PLUS table is also similar@@@Creating Table for the Muslim/Polish questions, which have very different structure to the rest of data
#NL2_1_1: NL2_4_3 = the table questions on p. 11 of codebook concerning muslims, and NL4 starting items are
#for the sae q's but Polish. Articles had these questions based on their primary topic, as stated on p. 10 of 
# the codebook '(V6) = [0124 | 0501 thru 0507 | 0704 | 1204 | 1603]'. Therefore only articles/news with these 
#topics are included in this table. It also includes their ID number and primary topic as keys @@??

MUS_POL <- CA %>%
  select(ID, V2, V6, NL2_1_1 : NL2_4_3, NL3, NL4_1_1 : NL4_4_3, NL5) %>%
  filter(V6 == "Economy: Free movement of people within the EU (common market: including the Schengen agreement)" | V6 == "Immigration : EU immigration policy - regulating immigration from outside the EU (e.g. refugees, asylum, EU border" | V6 == "Immigration : Migration / immigration policy – regulating migration within the EU (e.g. labour migration from East" | V6 == "Immigration : Immigration policy (non-EU) - regulating immigration from outside the EU" | V6 == "Immigration : Immigrant integration" | V6 =="Immigration : Multiculturalism (cultural diversity, cultural plurality)" | V6 == "Immigration : Anti-Islam" | V6 == "Immigration : Other immigration topics" | V6 == "Culture and Other: Religion" | V6 == "Citizens’ rights: Immigrant rights" | V6 == "Elections: Media coverage of the campaign") 

#create variable "Origins" as factor with levels of different Nationalities: Muslims / followers of Islam, Moroccan origins, Turkish origins, Other national origins, Poles, Other specific Middle or Eastern nationals (from the EU), Middle and/or Eastern Europeans in general  (from the EU), Eastern European, but not EU (Russia, Ukraine, Belarus, Moldova)

#create variable "origin" with value 1 to 8 for different origins in variables NL2_1_1:NL2_4_3 and NL4_1_1:NL4_4_3

#levels: 1 = Muslims/followers of Islam, 2 = Moroccan origins, 3 = Turkish origins, 4 = Other national origins, 5 = Poles, 6 = other specific middle or eastern nationals (from the EU)

getOrigin <- function(datatable) {
  case_when(
    datatable$NL2_1_1 == 1 ~ 1,
    datatable$NL2_1_2 == 1 ~ 1,
    datatable$NL2_1_3 == 1 ~ 1, 
    datatable$NL2_2_1 == 1 ~ 2,
    datatable$NL2_2_2 == 1 ~ 2,
    datatable$NL2_2_3 == 1 ~ 2, 
    datatable$NL2_3_1 == 1 ~ 3,
    datatable$NL2_3_2 == 1 ~ 3,
    datatable$NL2_3_3 == 1 ~ 3,
    datatable$NL2_4_1 == 1 ~ 4,
    datatable$NL2_4_2 == 1 ~ 4,
    datatable$NL2_4_3 == 1 ~ 4,
    datatable$NL4_1_1 == 1 ~ 5,
    datatable$NL4_1_2 == 1 ~ 5,
    datatable$NL4_1_3 == 1 ~ 5, 
    datatable$NL4_2_1 == 1 ~ 6,
    datatable$NL4_2_2 == 1 ~ 6,
    datatable$NL4_2_3 == 1 ~ 6,
    datatable$NL4_3_1 == 1 ~ 7,
    datatable$NL4_3_2 == 1 ~ 7,
    datatable$NL4_3_3 == 1 ~ 7, 
    datatable$NL4_4_1 == 1 ~ 8,
    datatable$NL4_4_2 == 1 ~ 8,
    datatable$NL4_4_3 == 1 ~ 8
    )
}

#call function origin
origin <-  getOrigin(MUS_POL)
MUS_POL$origin <- origin

#do the same for location
#Levels: 1 = in the Netherlands, 2 = In another country, 3 = in the "home" country

getLocation <- function(datatable) {
  case_when(
    datatable$NL2_1_1 == 1 ~ 1,
    datatable$NL2_1_2 == 1 ~ 2,
    datatable$NL2_1_3 == 1 ~ 3,
    datatable$NL2_2_1 == 1 ~ 1,
    datatable$NL2_2_2 == 1 ~ 2,
    datatable$NL2_2_3 == 1 ~ 3,
    datatable$NL2_3_1 == 1 ~ 1,
    datatable$NL2_3_2 == 1 ~ 2,
    datatable$NL2_3_3 == 1 ~ 3,
    datatable$NL2_4_1 == 1 ~ 1,
    datatable$NL2_4_2 == 1 ~ 2,
    datatable$NL2_4_3 == 1 ~ 3,
    datatable$NL4_2_1 == 1 ~ 1,
    datatable$NL4_2_2 == 1 ~ 2,
    datatable$NL4_2_3 == 1 ~ 3,
    datatable$NL4_3_1 == 1 ~ 1,
    datatable$NL4_3_2 == 1 ~ 2,
    datatable$NL4_3_3 == 1 ~ 3,
    datatable$NL4_1_1 == 1 ~ 1,
    datatable$NL4_1_2 == 1 ~ 2,
    datatable$NL4_1_3 == 1 ~ 3
  )
}

#call function location
location <-  getLocation(MUS_POL)
MUS_POL$location <- location

#do the same for evaluation
#as in Codebook, Levels: 1 = no evaluation, 2 = negative, 3= rather negative, 4 = balanced/mixed, 5 = rather positive, 6 = positive

getEvaluation <- function(datatable) {
  case_when(
    !is.na(datatable$NL3) ~ datatable$NL3,
    !is.na(datatable$NL5) ~ datatable$NL5
  )
}

#call function evaluation
MUS_POL$evaluation <-  getEvaluation(MUS_POL)

#remove unnecessary variables
MUS_POL$NL2_1_1 <- NULL
MUS_POL$NL2_1_2 <- NULL
MUS_POL$NL2_1_3 <- NULL
MUS_POL$NL2_2_1 <- NULL
MUS_POL$NL2_2_2 <- NULL
MUS_POL$NL2_2_3 <- NULL
MUS_POL$NL2_3_1 <- NULL
MUS_POL$NL2_3_2 <- NULL
MUS_POL$NL2_3_3 <- NULL
MUS_POL$NL2_4_1 <- NULL
MUS_POL$NL2_4_2 <- NULL
MUS_POL$NL2_4_3 <- NULL

MUS_POL$NL3 <- NULL

MUS_POL$NL4_1_1 <- NULL
MUS_POL$NL4_1_2 <- NULL
MUS_POL$NL4_1_3 <- NULL
MUS_POL$NL4_2_1 <- NULL
MUS_POL$NL4_2_2 <- NULL
MUS_POL$NL4_2_3 <- NULL
MUS_POL$NL4_3_1 <- NULL
MUS_POL$NL4_3_2 <- NULL
MUS_POL$NL4_3_3 <- NULL
MUS_POL$NL4_4_1 <- NULL
MUS_POL$NL4_4_2 <- NULL
MUS_POL$NL4_4_3 <- NULL

MUS_POL$NL5 <- NULL

CA_FIXED_TV <- CA %>%
  filter(V4 == "NOS Journaal" | V4 == "RTL Nieuws")%>% #Exclude (filter out) the newspapers
  select(V2,	V4, TV1, TV2)


APRIL <- CA %>% #Table with variables coded only after april the 17th 
  select(V2, date, V9,	V9b,	V10a : V10c,	NL6_1_1 : NL6_3_4,	NL8a,	NL9a_1 : NL9a_5_TEXT, NL9b_1 : NL9b_5_TEXT, NL9c1 : NL9c5_TEXT, NL9d1 : NL9d5_TEXT,	NL10a : NL10d, NL11a1 : NL23d5_TEXT,	NL34 : NL41f, NL42a_a : NL42b_SP_f, NL43, NL44, NL45 : NL47) %>% 
filter(date >= as.Date("2014-04-17")) #and include cases only after filtered date, 17th April

  

```

```{r}
#Creating a table for the PVV 50PLUS articles. 
#NOTE: This table @@was not further tidied as tidying would be similar to what was demonstrated with the MUS/POLE table above.
#Therefore, variables required by group members for their own analyses were tidied as required, rather than restructuring this entire table. 
#See for example PVVH table used by Haylee. 

PVV50 <- CA %>% #@@Ask whether we have to totally redo this table or not.
  filter(date >= as.Date("2014-04-17"))%>% #and include cases only after filtered date, 17th April
  dplyr::select(V2, NL8a, NL8b, NL8c, NL8d, NL9a_1:NL9a_5_TEXT, NL9b_1:NL9b_5_TEXT, NL9c1:NL9c5_TEXT, NL9d1:NL9d5_TEXT, NL10a, NL10b, NL10c, NL10d, NL11a1:NL11a5_TEXT, NL11b1:NL11b5_TEXT, NL11c1:NL11c5_TEXT, NL11d1:NL11d5_TEXT, NL12a, NL12b, NL12c, NL12d, NL13a1:NL13a5_TEXT, NL13b1:NL13b5_TEXT, NL13c1:NL13c5_TEXT, NL13d1:NL13d5_TEXT, NL14a, NL14b, NL14c, NL14d,  NL15a1:NL15a5_TEXT, NL15b1:NL15b5_TEXT, NL15c1:NL15c5_TEXT, NL15d1:NL15d5_TEXT, NL16a, NL16b, NL16c, NL16d, NL17a1:NL17a5_TEXT, NL17b1:NL17b5_TEXT, NL17c1:NL17c5_TEXT, NL17d1:NL17d5_TEXT, NL18a, NL18b, NL18c, NL18d, NL19a1:NL19a5_TEXT, NL19b1:NL19b5_TEXT, NL19c1:NL19c5_TEXT, NL19d1:NL19d5_TEXT, NL20a, NL20b, NL20c, NL20d, NL21a1:NL21a5_TEXT, NL21b1:NL21b5_TEXT, NL21c1:NL21c5_TEXT, NL21d1:NL21d5_TEXT, NL22a, NL22b, NL22c, NL22d, NL23a1:NL23a5_TEXT, NL23b1:NL23b5_TEXT, NL23c1:NL23c5_TEXT, NL23d1:NL23d5_TEXT)




  
```

```{r Louelle Pesurnaij, echo=FALSE}
#Create tables with variables for Louelle's visualization
Louelle_ESS <- ESSclean %>% select(RESPNR, Wavevalue, date, w1_q10_1, w1_q10_2, w1_q10_3,w1_q10_4, w2_q7_1, w2_q7_2, w2_q7_3, w2_q7_4, w3_q11_1, w3_q11_2, w3_q11_3, w3_q11_4, w4_q13_1, w4_q13_2, w4_q13_3, w4_q13_4, w1_q49_1, w1_q49_2, w1_q50_1, w1_q50_2, w1_q50_6, w2_q44_1, w2_q44_2, w2_q45_1, w2_q45_2, w2_q45_6, w3_q43_1, w3_q43_2, w3_q44_1, w3_q44_2, w3_q44_6, w4_q47_1, w4_q47_2, w4_q48_1, w4_q48_2, w4_q48_6,w1_q51_2, w2_q46_2, w3_q45_2, w4_q49_2)
Louelle_CA <- ALL_FIXED %>% select(date, V6Topic, V4)

#Separate the Likert-scale numbers that measure Political Cynicism from the description (characters)
Louelle_ESS <- separate(Louelle_ESS, w1_q10_1, into = c("w1_q10_1", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w1_q10_2, into = c("w1_q10_2", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w1_q10_3, into = c("w1_q10_3", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w1_q10_4, into = c("w1_q10_4", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w2_q7_1, into = c("w2_q7_1", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w2_q7_2, into = c("w2_q7_2", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w2_q7_3, into = c("w2_q7_3", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w2_q7_4, into = c("w2_q7_4", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w3_q11_1, into = c("w3_q11_1", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w3_q11_2, into = c("w3_q11_2", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w3_q11_3, into = c("w3_q11_3", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w3_q11_4, into = c("w3_q11_4", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w4_q13_1, into = c("w4_q13_1", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w4_q13_2, into = c("w4_q13_2", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w4_q13_3, into = c("w4_q13_3", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w4_q13_4, into = c("w4_q13_4", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w1_q49_1, into = c("W1Q491", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w1_q49_2, into = c("W1Q492", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w1_q50_1, into = c("W1Q501", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w1_q50_2, into = c("W1Q502", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w1_q50_6, into = c("W1Q506", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w1_q51_2, into = c("W1Q512", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w2_q44_1, into = c("W2Q441", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w2_q44_2, into = c("W2Q442", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w2_q45_1, into = c("W2Q451", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w2_q45_2, into = c("W2Q452", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w2_q45_6, into = c("W2Q456", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w2_q46_2, into = c("W2Q462", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w3_q43_1, into = c("W3Q431", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w3_q43_2, into = c("W3Q432", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w3_q44_1, into = c("W3Q441", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w3_q44_2, into = c("W3Q442", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w3_q44_6, into = c("W3Q446", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w3_q45_2, into = c("W3Q452", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w4_q47_1, into = c("W4Q471", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w4_q47_2, into = c("W4Q472", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w4_q48_1, into = c("W4Q481", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w4_q48_2, into = c("W4Q482", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w4_q48_6, into = c("W4Q486", "varvalue"), sep = " ")
Louelle_ESS <- separate(Louelle_ESS, w4_q49_2, into = c("W4Q492", "varvalue"), sep = " ")

# Remove the columns that have the description (character) of the Likert-scale that measures Political Cynicism
Louelle_ESS$varvalue <- NULL

# Change the Likert-scales that measure Political Cynicism from character to numeric
Louelle_ESS$w1_q10_1 <- as.numeric(as.character(Louelle_ESS$w1_q10_1))
Louelle_ESS$w1_q10_2 <- as.numeric(as.character(Louelle_ESS$w1_q10_2))
Louelle_ESS$w1_q10_3 <- as.numeric(as.character(Louelle_ESS$w1_q10_3))
Louelle_ESS$w1_q10_4 <- as.numeric(as.character(Louelle_ESS$w1_q10_4))
Louelle_ESS$w2_q7_1 <- as.numeric(as.character(Louelle_ESS$w2_q7_1))
Louelle_ESS$w2_q7_2 <- as.numeric(as.character(Louelle_ESS$w2_q7_2))
Louelle_ESS$w2_q7_3 <- as.numeric(as.character(Louelle_ESS$w2_q7_3))
Louelle_ESS$w2_q7_4 <- as.numeric(as.character(Louelle_ESS$w2_q7_4))
Louelle_ESS$w3_q11_1 <- as.numeric(as.character(Louelle_ESS$w3_q11_1))
Louelle_ESS$w3_q11_2 <- as.numeric(as.character(Louelle_ESS$w3_q11_2))
Louelle_ESS$w3_q11_3 <- as.numeric(as.character(Louelle_ESS$w3_q11_3))
Louelle_ESS$w3_q11_4 <- as.numeric(as.character(Louelle_ESS$w3_q11_4))
Louelle_ESS$w4_q13_1 <- as.numeric(as.character(Louelle_ESS$w4_q13_1))
Louelle_ESS$w4_q13_2 <- as.numeric(as.character(Louelle_ESS$w4_q13_2))
Louelle_ESS$w4_q13_3 <- as.numeric(as.character(Louelle_ESS$w4_q13_3))
Louelle_ESS$w4_q13_4 <- as.numeric(as.character(Louelle_ESS$w4_q13_4))
Louelle_ESS$W1Q491 <- as.numeric(as.character(Louelle_ESS$W1Q491))
Louelle_ESS$W1Q492 <- as.numeric(as.character(Louelle_ESS$W1Q492))
Louelle_ESS$W1Q501 <- as.numeric(as.character(Louelle_ESS$W1Q501))
Louelle_ESS$W1Q502 <- as.numeric(as.character(Louelle_ESS$W1Q502))
Louelle_ESS$W1Q506 <- as.numeric(as.character(Louelle_ESS$W1Q506))
Louelle_ESS$W1Q512 <- as.numeric(as.character(Louelle_ESS$W1Q512))
Louelle_ESS$W2Q441 <- as.numeric(as.character(Louelle_ESS$W2Q441))
Louelle_ESS$W2Q442 <- as.numeric(as.character(Louelle_ESS$W2Q442))
Louelle_ESS$W2Q451 <- as.numeric(as.character(Louelle_ESS$W2Q451))
Louelle_ESS$W2Q452 <- as.numeric(as.character(Louelle_ESS$W2Q452))
Louelle_ESS$W2Q456 <- as.numeric(as.character(Louelle_ESS$W2Q456))
Louelle_ESS$W2Q462 <- as.numeric(as.character(Louelle_ESS$W2Q462))
Louelle_ESS$W3Q431 <- as.numeric(as.character(Louelle_ESS$W3Q431))
Louelle_ESS$W3Q432 <- as.numeric(as.character(Louelle_ESS$W3Q432))
Louelle_ESS$W3Q441 <- as.numeric(as.character(Louelle_ESS$W3Q441))
Louelle_ESS$W3Q442 <- as.numeric(as.character(Louelle_ESS$W3Q442))
Louelle_ESS$W3Q446 <- as.numeric(as.character(Louelle_ESS$W3Q446))
Louelle_ESS$W3Q452 <- as.numeric(as.character(Louelle_ESS$W3Q452))
Louelle_ESS$W4Q471 <- as.numeric(as.character(Louelle_ESS$W4Q471))
Louelle_ESS$W4Q472 <- as.numeric(as.character(Louelle_ESS$W4Q472))
Louelle_ESS$W4Q481 <- as.numeric(as.character(Louelle_ESS$W4Q481))
Louelle_ESS$W4Q482 <- as.numeric(as.character(Louelle_ESS$W4Q482))
Louelle_ESS$W4Q486 <- as.numeric(as.character(Louelle_ESS$W4Q486))
Louelle_ESS$W4Q492 <- as.numeric(as.character(Louelle_ESS$W4Q492))

# Calculate the average mean of the construct Political Cynisism (by wave)
Louelle_ESS$Mean <- ifelse(Louelle_ESS$Wavevalue == 1, rowMeans(subset(Louelle_ESS, select = c(w1_q10_1, w1_q10_2, w1_q10_3, w1_q10_4)), na.rm = TRUE), ifelse(Louelle_ESS$Wavevalue == 2, rowMeans(subset(Louelle_ESS, select = c(w2_q7_1, w2_q7_2, w2_q7_3, w2_q7_4)), na.rm = TRUE), ifelse(Louelle_ESS$Wavevalue == 3, rowMeans(subset(Louelle_ESS, select = c(w3_q11_1, w3_q11_2, w3_q11_3, w3_q11_4)), na.rm = TRUE), ifelse(Louelle_ESS$Wavevalue == 4, rowMeans(subset(Louelle_ESS, select = c(w4_q13_1, w4_q13_2, w4_q13_3, w4_q13_4)), na.rm = TRUE), NA))))

Louelle_ESS$w1_q10_1 <- NULL
Louelle_ESS$w1_q10_2 <- NULL
Louelle_ESS$w1_q10_3 <- NULL
Louelle_ESS$w1_q10_4 <- NULL
Louelle_ESS$w2_q7_1 <- NULL
Louelle_ESS$w2_q7_2 <- NULL
Louelle_ESS$w2_q7_3 <- NULL
Louelle_ESS$w2_q7_4 <- NULL
Louelle_ESS$w3_q11_1 <- NULL
Louelle_ESS$w3_q11_2 <- NULL
Louelle_ESS$w3_q11_3 <- NULL
Louelle_ESS$w3_q11_4 <- NULL
Louelle_ESS$w4_q13_1 <- NULL
Louelle_ESS$w4_q13_2 <- NULL
Louelle_ESS$w4_q13_3 <- NULL
Louelle_ESS$w4_q13_4 <- NULL

# Filter Content Analysis-data to only "Elections" articles in Dutch media (de Telegraaf, de Volkskrant, NOS Journaal, NRC Handelsblad, nu.nl and RTL Nieuws)
Louelle_CA <- Louelle_CA %>% filter(V6Topic == "Elections") %>% filter(V4 %in% c("de Telegraaf", "de Volkskrant", "NOS Journaal", "NRC Handelsblad", "nu.nl", "RTL Nieuws")) %>% count(date)
Louelle_CA$n <- as.numeric(as.integer(Louelle_CA$n))

# Filter Survey-data so only respondents who are exposed to one of the media outlets (de Telegraaf, de Volkskrant, NOS Journaal, NRC Handelsblad, nu.nl and RTL Nieuws) at least once a week 
Louelle_ESS$sum <- ifelse(Louelle_ESS$Wavevalue == 1,rowSums(subset(Louelle_ESS, select = c(W1Q491, W1Q492, W1Q501, W1Q502, W1Q506)), na.rm = TRUE), ifelse(Louelle_ESS$Wavevalue == 2, rowSums(subset(Louelle_ESS, select = c(W2Q441, W2Q442, W2Q451, W2Q452, W2Q452, W2Q462)), na.rm = TRUE), ifelse(Louelle_ESS$Wavevalue == 3, rowSums(subset(Louelle_ESS, select = c(W3Q431, W3Q432, W3Q441, W3Q442, W3Q452)), na.rm = TRUE), ifelse(Louelle_ESS$Wavevalue == 4, rowSums(subset(Louelle_ESS, select = c(W4Q471, W4Q472, W4Q481, W4Q482, W4Q492)), na.rm = TRUE), NA))))
Louelle_ESS <- Louelle_ESS %>% filter(sum >= 1)

# Merge content analysis data with survey data
Louelle_ALL <- merge(Louelle_ESS, Louelle_CA, by = c("date"), all = TRUE)

# Plot the variables over time
p <- ggplot(data = Louelle_ALL, aes(date))
p <- p + geom_smooth(aes(y = n, color = "Amount of articles about elections"), se = FALSE)
p <- p + geom_point(aes(y = Mean), position = "jitter", color = "sky blue", alpha = 1/8)
p <- p + geom_smooth(aes(y = Mean, color = "Polytical cynicism"), se = FALSE)
p <- p + labs(x = "Date", title = "(Second-Level) Agenda Setting:", subtitle = "The influence of Dutch media coverage about 2014 EU elections on political cynicism", y = "Political cynicism")
p <- p + scale_y_continuous(limits = c(1, 7), breaks = c(1, 2, 3, 4, 5, 6, 7), sec.axis = sec_axis(name = "Amount of articles", ~ . * 21 / 7))
p <- p + theme_minimal(base_size = 11)
p <- p + theme(legend.position = "bottom")
p <- p + scale_colour_manual(name = " ", values = c("deep sky blue 4", "sky blue 2"))
p <- p + annotate("text", x=as.Date("2014-05-22", "%Y-%m-%d"), y=5.5, label= "2014 EU election", size=3, angle=19)
p <- p + annotate("text", x=as.Date("2014-03-10", "%Y-%m-%d"), y=6.7, label= "Local elections in EU Countries", size=3, angle=19)
p <- p + geom_segment(aes(x = as.Date("2014-05-20", "%Y-%m-%d"), y=4.85, xend = as.Date("2014-05-20", "%Y-%m-%d"), yend = 5.25), size = 0.2, color = "deep sky blue 4", linetype = "dotted")
p <- p + geom_segment(aes(x = as.Date("2014-03-17", "%Y-%m-%d"), y=6.25, xend = as.Date("2014-03-17", "%Y-%m-%d"), yend = 6.7), size = 0.3, color = "deep sky blue 4", linetype = "dotted")
p <- p + geom_segment(aes(x = as.Date("2014-02-28", "%Y-%m-%d"), y=5.8, xend = as.Date("2014-02-28", "%Y-%m-%d"), yend = 6.2), size = 0.2, color = "deep sky blue 4", linetype = "dotted")
p <- p + theme(panel.grid.minor = element_blank())
p
```