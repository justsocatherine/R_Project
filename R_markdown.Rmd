---
title: "@@Add title"
author: "Katerin Kunfermann, Haylee Kelsall 11665424, 12225223@@@@add names, Student numbers etc"
date: "17 January 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


#@@Jobs before handing in: 
#Check code is actually tide for the group part. Is it as concise as possible? e.g. replace nl1a, nl1b, nl1c with nl1a:nl1c. 
#Someone needs to go through CA code, and check 'ID' is in everything. Unforutnately V2 was not a unique ID but instead unique only to coders GAH
#Check there is enough detail given in tiying explanations, including e.g. 'viewed it using head(x) and checked compared to...'
#Check entire thing ACTUALLY runs
#Check spelling, cntrl+f search for @ signs notes to be done/removed
#WRITE TEXT INTRODUCING THE OVERALL INFOGRAPHIC... Somehow
#Do all visualisation fit together somehow in terms of style?
#All names on the document? Title? Date? Etc. 
#How does the text knit? 
#Set code chunks to echo = False
#@@More to be added to list of shit to do... 

##CONTENT ANALYSIS SET STILL NEEDS TO BE CHECKED FOR OTHER RULES OF TIDYING!!!!!!!!


```



```{r import survey data and access packages}
library(tidyverse) #access tidyverse
library(lubridate) #lubridate (@@remove this if we don't actually use it in the end)
#@@add other additional packages needed here - e.g. for interactive plots etc. 

CA <- read_csv("Dataset MCA EPE 2014 NL FINAL.csv") #Read content analysis file, store under CA
# @ later remove this so also contetn analysis is imported here

ESS <- read_csv("All waves GENERAL.csv") # read survey file, store under ESS (Election Study Survey)

#Tidying the data set. Step ONE: Seperate respondent fixed characteristics, with help of code book.
#Examples of these: demographics, big 5 personality traits etc. Here the RESPONDENT is the unit. 
#We also want to include here a column for the waves which the participant was in, we only have the 'GENERAL' panel data so not neccessary to create additional columns for other panels. 

ESS %>%
  summarise(n_RESPS = n_distinct(RESPNR)) #Check all respondent IDs unique. Respondent ID will be #used as our primary key in this table.
# @ wave weighting should probabbly be in the wave'd variables seeing as they apply to each wave, fix this later @H

#tidy columns respondent ID and Waves
ESS %>% count(WAVES) #First count the number of respondents participating in each level of 'WAVES'.

#Wave 1
ESS$wave1 <- ifelse(ESS$WAVES == "All waves", 1, ifelse(ESS$WAVES == "Only wave 1", 1, ifelse(ESS$WAVES == "Wave 1 and 2", 1, ifelse(ESS$WAVES == "Wave 1, 2 and 3", 1, 0)))) 
#Create new column called "wave1" in ESS, assign the value 1 = YES 0 = NO. (Note all participants were in at least wave1) 

#Wave 2
ESS$wave2 <- ifelse(ESS$WAVES == "All waves", 1, ifelse(ESS$WAVES == "Wave 1 and 2", 1, ifelse(ESS$WAVES == "Wave 1, 2 and 3", 1, 0))) #Create new column called "wave2" in ESS, assign the value 1 = YES if respondent participated in wave 2, 0 = NO. 

#Wave 3
ESS$wave3 <- ifelse(ESS$WAVES == "All waves", 1, ifelse(ESS$WAVES == "Wave 1, 2 and 3", 1, 0)) 
#Create new column called "wave3" in ESS, assign the value 1 = YES if respondent participated in wave 3, 0 = NO. 

#Wave 4
ESS$wave4 <- ifelse(ESS$WAVES == "All waves", 1, 0) #Create new column called "wave4" in ESS, assign the value 1 = YES if respondent participated in wave 4, 0 = NO.

RESP_DEMOG <- ESS %>%
  group_by(INTNR, RESPNR,	SAMPLE,	WAVES,	GEWICHTA1_w1,	GEWICHTA1_w2,	GEWICHTA1_w3,	GEWICHTA1_w4,	GSL,	LFT,	OPLA,	NIELSENCBS,	GEZINSGROOTTE,	POL2012, w1_q5_1, w1_q5_2, w1_q5_3, w1_q5_4, w1_q17_1, w1_q17_2, w1_q17_3, w1_q17_4, w1_q23, w1_q24_1, w1_q24_2, w1_q24_3, w1_q29, w1_q30_1,w1_q30_2,	w1_q30_3,	w1_q30_4,	w1_q30_5,	w1_q30_6,	w1_q30_7,	w1_q30_8,	w1_q30_9,	w1_q30_10,	w1_q30_11, w1_q31_1,	w1_q31_2,	w1_q31_3,	w1_q31_4,	w1_q31_5,	w1_q31_6,	w1_q31_7,	w1_q31_8,	w1_q31_9,	w1_q32_1,	w1_q32_2,	w1_q32_3,	w1_q32_4, w1_q57_1,	w1_q57_2,	w1_q57_3,	w1_q57_4,	w1_q57_5,	w1_q57_6,	w1_q57_7,	w1_q57_8,	w1_q58_1,	w1_q58_2,	w1_q58_3,	w1_q58_4,	w1_q58_5,	w1_q58_6,	w1_q58_7,	w1_q58_8,	w1_q58_9,	w1_q58_10,	w1_q59,	w1_q60,	w1_q61,	w1_q62,	w1_q64,	w1_q65,	w1_q66,	w1_q67,	w1_q68,	w1_q68_YES, w2_q25,	w2_q26_1,	w2_q26_2,	w2_q26_3,	w2_q26_4,	w2_q26_5,	w2_q26_6,	w2_q26_7,	w2_q26_8,	w2_q26_9,	w2_q26_10,	w2_q26_11,	w2_q27_1,	w2_q27_2,	w2_q27_3,	w2_q27_4,	w2_q27_5,	w2_q27_6,	w2_q27_7,	w2_q27_8,	w2_q27_9,	w2_q28_1,	w2_q28_2,	w2_q28_3,	w2_q28_4,	w2_q28_5,	w2_q28_6,	w2_q28_7,	w2_q28_8,	w2_q28_9,	w2_q28_10,	w2_q28_11,	w2_q29,	w2_q30,	w2_q30_OTHER_LOCAL,	w2_q30_OTHER,	w2_q31,	w2_q32_1,	w2_q32_2,	w2_q32_3,	w2_q32_4,	w2_q32_5,	w2_q32_OTHER,	w2_q33_1,	w2_q33_2,	w2_q33_3,	w2_q33_4,	w2_q33_5,	w2_q33_6,	w2_q33_7,	w2_q33_8,	w2_q33_9,	w2_q33_10,	w2_q33_11,	w2_q33_12,	w2_q33_13,	w2_q33_14,	w2_q33_OTHER_LOCAL,	w2_q33_OTHER,	w2_q50_1,	w2_q50_2,	w2_q50_3,	w2_q50_4,	w2_q50_5,	w2_q50_6,	w2_q51,	w2_q52_1,	w2_q52_2,	w2_q52_3,	w2_q52_4,	w2_q52_5,	w2_q53_1,	w2_q53_2,	w2_q54,	w2_q55,	w2_q56_1,	w2_q56_2,	w2_q56_3,	w2_q56_4, w2_q61_1,	w2_q61_2,	w2_q62_CONDITION1,	w2_q62_CONDITION2, w2_q63,	w2_q65, w3_q49TRUE_1,	w3_q49TRUE_2,	w3_q49TRUE_3,	w3_q49TRUE_4,	w3_q49TRUE_5,	w3_q49TRUE_6,	w3_q49TRUE_7,	w3_q49_1,	w3_q49_2,	w3_q49_3,	w3_q49_4,	w3_q49_5,	w3_q49_6,	w3_q49_7, w3_q56_CONDITION1_1,	w3_q56_CONDITION1_2,	w3_q56_CONDITION1_3,	w3_q56_CONDITION1_4,	w3_q56_CONDITION2_1,	w3_q56_CONDITION2_2,	w3_q56_CONDITION2_3,	w3_q56_CONDITION2_4,	w3_q56_TIMESTAMP, w3_q59_1,	w3_q59_2,	w3_q59_3,	w3_q60_1,	w3_q60_2,	w3_q60_3,	w3_q60_4, w4_q7,	w4_q8,	w4_q9, w4_q27, w4_q41_1,	w4_q41_2,	w4_q41_3,	w4_q41_4,	w4_q41_5,	w4_q41_6,	w4_q41_7,	w4_q41_8,	w4_q41_9,	w4_q41_10,	w4_q41_11, w4_q41_12,  w4_q43_1,	w4_q43_2,	w4_q43_3,	w4_q43_4,	w4_q43_5,	w4_q43_6,	w4_q43_7,	w4_q43_8,	w4_q43_9,	w4_q43_10,	w4_q43_11,	w4_q43_12, w4_q51_1,	w4_q51_2,	w4_q51_3,	w4_q51_4,	w4_q51_5,	w4_q51_OTHER,	w4_q52_1,	w4_q52_2,	w4_q52_3,	w4_q52_4,	w4_q52_5,	w4_q52_6,	w4_q52_7,	w4_q52_8,	w4_q52_9,	w4_q52_10,	w4_q52_11,	w4_q52_12,	w4_q52_13,	w4_q52_OTHER, w4_q57, w4_q62_1,	w4_q62_2,	w4_q62_3,	w4_q62_4,	w4_q62_5,	w4_q62_6,	w4_q62_7) %>%
summarise()
RESP_DEMOG #Now we have a table with all fixed characteristics of respondents. We still need to check every single variable that it meets rules of tidy data even thouh now at least 'each unit has its own table' is PARTLY fulfilled with this table @@

#@@ NOTE!!! SOME VARIABLES ABOVE HAVE BEEN RECODED already into standard variable names already such as w1_q61 is actualy OPLA (opleiding) 

#Change W3_Q56
RESP_DEMOG_test <- RESP_DEMOG %>% group_by(RESPNR, w3_q56_CONDITION1_1, w3_q56_CONDITION1_2, w3_q56_CONDITION1_3, w3_q56_CONDITION1_4, w3_q56_CONDITION2_1, w3_q56_CONDITION2_2, w3_q56_CONDITION2_3, w3_q56_CONDITION2_4) %>% select(RESPNR, w3_q56_CONDITION1_1, w3_q56_CONDITION1_2, w3_q56_CONDITION1_3, w3_q56_CONDITION1_4, w3_q56_CONDITION2_1, w3_q56_CONDITION2_2, w3_q56_CONDITION2_3, w3_q56_CONDITION2_4)

#Splitting the Experiment-data
RESP_DEMOG$W3_Q56_CONDITION <- ifelse(!is.na(RESP_DEMOG$w3_q56_CONDITION1_1), 1, ifelse(!is.na(RESP_DEMOG$w3_q56_CONDITION1_2), 1, ifelse(!is.na(RESP_DEMOG$w3_q56_CONDITION1_3), 1, ifelse(!is.na(RESP_DEMOG$w3_q56_CONDITION1_4), 1, ifelse(!is.na(RESP_DEMOG$w3_q56_CONDITION2_1), 2, ifelse(!is.na(RESP_DEMOG$w3_q56_CONDITION2_2), 2, ifelse(!is.na(RESP_DEMOG$w3_q56_CONDITION2_3), 2, ifelse(!is.na(RESP_DEMOG$w3_q56_CONDITION2_4), 2, NA)))))))) 

```


```{r pressure, echo=FALSE}
plot(pressure)
```



```{r Spread the waveeeeees}
#select relevant variables for all waves
ESSclean <- select(ESS, -c(INTNR, SAMPLE,	GEWICHTA1_w1,	GEWICHTA1_w2,	GEWICHTA1_w3,	GEWICHTA1_w4,	GSL,	LFT,	OPLA,	NIELSENCBS,	GEZINSGROOTTE,	POL2012, w1_q5_1, w1_q5_2, w1_q5_3, w1_q5_4, w1_q17_1, w1_q17_2, w1_q17_3, w1_q17_4, w1_q23, w1_q24_1, w1_q24_2, w1_q24_3, w1_q29, w1_q30_1,w1_q30_2,	w1_q30_3,	w1_q30_4,	w1_q30_5,	w1_q30_6,	w1_q30_7,	w1_q30_8,	w1_q30_9,	w1_q30_10,	w1_q30_11, w1_q31_1,	w1_q31_2,	w1_q31_3,	w1_q31_4,	w1_q31_5,	w1_q31_6,	w1_q31_7,	w1_q31_8,	w1_q31_9,	w1_q32_1,	w1_q32_2,	w1_q32_3,	w1_q32_4, w1_q57_1,	w1_q57_2,	w1_q57_3,	w1_q57_4,	w1_q57_5,	w1_q57_6,	w1_q57_7,	w1_q57_8,	w1_q58_1,	w1_q58_2,	w1_q58_3,	w1_q58_4,	w1_q58_5,	w1_q58_6,	w1_q58_7,	w1_q58_8,	w1_q58_9,	w1_q58_10,	w1_q59,	w1_q60,	w1_q61,	w1_q62,	w1_q64,	w1_q65,	w1_q66,	w1_q67,	w1_q68,	w1_q68_YES, w2_q25,	w2_q26_1,	w2_q26_2,	w2_q26_3,	w2_q26_4,	w2_q26_5,	w2_q26_6,	w2_q26_7,	w2_q26_8,	w2_q26_9,	w2_q26_10,	w2_q26_11,	w2_q27_1,	w2_q27_2,	w2_q27_3,	w2_q27_4,	w2_q27_5,	w2_q27_6,	w2_q27_7,	w2_q27_8,	w2_q27_9,	w2_q28_1,	w2_q28_2,	w2_q28_3,	w2_q28_4,	w2_q28_5,	w2_q28_6,	w2_q28_7,	w2_q28_8,	w2_q28_9,	w2_q28_10,	w2_q28_11,	w2_q29,	w2_q30,	w2_q30_OTHER_LOCAL,	w2_q30_OTHER,	w2_q31,	w2_q32_1,	w2_q32_2,	w2_q32_3,	w2_q32_4,	w2_q32_5,	w2_q32_OTHER,	w2_q33_1,	w2_q33_2,	w2_q33_3,	w2_q33_4,	w2_q33_5,	w2_q33_6,	w2_q33_7,	w2_q33_8,	w2_q33_9,	w2_q33_10,	w2_q33_11,	w2_q33_12,	w2_q33_13,	w2_q33_14,	w2_q33_OTHER_LOCAL,	w2_q33_OTHER,	w2_q50_1,	w2_q50_2,	w2_q50_3,	w2_q50_4,	w2_q50_5,	w2_q50_6,	w2_q51,	w2_q52_1,	w2_q52_2,	w2_q52_3,	w2_q52_4,	w2_q52_5,	w2_q53_1,	w2_q53_2,	w2_q54,	w2_q55,	w2_q56_1,	w2_q56_2,	w2_q56_3,	w2_q56_4, w2_q61_1,	w2_q61_2,	w2_q62_CONDITION1,	w2_q62_CONDITION2, w2_q63,	w2_q65, w3_q49TRUE_1,	w3_q49TRUE_2,	w3_q49TRUE_3,	w3_q49TRUE_4,	w3_q49TRUE_5,	w3_q49TRUE_6,	w3_q49TRUE_7,	w3_q49_1,	w3_q49_2,	w3_q49_3,	w3_q49_4,	w3_q49_5,	w3_q49_6,	w3_q49_7, w3_q56_CONDITION1_1,	w3_q56_CONDITION1_2,	w3_q56_CONDITION1_3,	w3_q56_CONDITION1_4,	w3_q56_CONDITION2_1,	w3_q56_CONDITION2_2,	w3_q56_CONDITION2_3,	w3_q56_CONDITION2_4,	w3_q56_TIMESTAMP, w3_q59_1,	w3_q59_2,	w3_q59_3,	w3_q60_1,	w3_q60_2,	w3_q60_3,	w3_q60_4, w4_q7,	w4_q8,	w4_q9, w4_q27, w4_q41_1,	w4_q41_2,	w4_q41_3,	w4_q41_4,	w4_q41_5,	w4_q41_6,	w4_q41_7,	w4_q41_8,	w4_q41_9,	w4_q41_10,	w4_q41_11, w4_q41_12,  w4_q43_1,	w4_q43_2,	w4_q43_3,	w4_q43_4,	w4_q43_5,	w4_q43_6,	w4_q43_7,	w4_q43_8,	w4_q43_9,	w4_q43_10,	w4_q43_11,	w4_q43_12, w4_q51_1,	w4_q51_2,	w4_q51_3,	w4_q51_4,	w4_q51_5,	w4_q51_OTHER,	w4_q52_1,	w4_q52_2,	w4_q52_3,	w4_q52_4,	w4_q52_5,	w4_q52_6,	w4_q52_7,	w4_q52_8,	w4_q52_9,	w4_q52_10,	w4_q52_11,	w4_q52_12,	w4_q52_13,	w4_q52_OTHER, w4_q57, w4_q62_1,	w4_q62_2,	w4_q62_3,	w4_q62_4,	w4_q62_5,	w4_q62_6,	w4_q62_7, wave1, wave2, wave3, wave4))

#Change values 1 (=TRUE) to 2 (=participates in wave 2)
#Wave 1
ESSclean$wave1 <- ifelse(ESS$wave1 == 1, 1, NA)
#Wave 2
ESSclean$wave2 <- ifelse(ESS$wave2 == 1, 2, NA)
#Wave 3
ESSclean$wave3 <- ifelse(ESS$wave3 == 1, 3, NA)
#Wave 4
ESSclean$wave4 <- ifelse(ESS$wave4 == 1, 4, NA)

#Create one out of Wave 1, 2, 3, 4
ESSclean <- ESSclean %>% gather(Wave, Wavevalue, wave1:wave4, na.rm = TRUE, convert = FALSE, factor_key = FALSE)



#remove WAVES and Wave columns
ESSclean$Wave <- NULL

# Clean up date-variables
ESSclean$date <- ifelse(ESSclean$Wavevalue == 1, ESSclean$w1_DATUM, ifelse(ESSclean$Wavevalue == 2, ESSclean$w2_DATUM, ifelse(ESSclean$Wavevalue == 3, ESSclean$w3_DATUM, ifelse(ESSclean$Wavevalue == 4, ESSclean$w4_DATUM, NA))))

# Change date-variable from character to actual date
ESSclean <- transform(ESSclean, date = as.Date(as.character(date), "%Y%m%d"))

#LOUELLES BRILJANT INNOVATIVE IDEA
#Example: Create the variables for Political Knowledge (i.e. PolKnowl)
ESSclean$PolKnowl1 <- ifelse(ESSclean$Wavevalue == 1, ESSclean$w1_q18, ifelse(ESSclean$Wavevalue == 2, ESSclean$w2_q14, ifelse(ESSclean$Wavevalue == 3, ESSclean$w3_q19, ifelse(ESSclean$Wavevalue == 4, ESSclean$w4_q21, NA)))) #Create PolKnowl1
ESSclean$PolKnowl2 <- ifelse(ESSclean$Wavevalue == 1, ESSclean$w1_q19, ifelse(ESSclean$Wavevalue == 2, ESSclean$w2_q15, ifelse(ESSclean$Wavevalue == 3, ESSclean$w3_q20, ifelse(ESSclean$Wavevalue == 4, ESSclean$w4_q22, NA)))) #Create PolKnowl2
ESSclean$PolKnowl3 <- ifelse(ESSclean$Wavevalue == 1, ESSclean$w1_q20, ifelse(ESSclean$Wavevalue == 2, ESSclean$w2_q16, ifelse(ESSclean$Wavevalue == 3, ESSclean$w3_q21, ifelse(ESSclean$Wavevalue == 4, ESSclean$w4_q23, NA)))) #Create PolKnowl3
ESSclean$PolKnowl4 <- ifelse(ESSclean$Wavevalue == 1, ESSclean$w1_q21, ifelse(ESSclean$Wavevalue == 2, ESSclean$w2_q17, ifelse(ESSclean$Wavevalue == 3, ESSclean$w3_q22, ifelse(ESSclean$Wavevalue == 4, ESSclean$w4_q24, NA)))) #Create PolKnowl4
ESSclean$PolKnowl5 <- ifelse(ESSclean$Wavevalue == 1, ESSclean$w1_q22, ifelse(ESSclean$Wavevalue == 2, ESSclean$w2_q18, ifelse(ESSclean$Wavevalue == 3, ESSclean$w3_q23, ifelse(ESSclean$Wavevalue == 4, ESSclean$w4_q25, NA)))) #Create PolKnowl5

#PROOF THAT IT WORKS ( Example is a very indecisive respondent)
ESSclean %>% select(RESPNR, Wavevalue, w1_q18, w2_q14, w3_q19, w4_q21) %>% filter(RESPNR == 30016148	)
ESSclean %>% select(RESPNR, Wavevalue, PolKnowl1) %>% filter(RESPNR == 30016148	)


```

```{r - CA tidying chunk}

library(lubridate)

#First parse date in original object so all latter tables will already have a 'date' column. day = V3a, month = V3b, year = V3c.
CA$date <- with(CA, dmy(sprintf('%02d%02d%02d', V3a, V3b, V3c))) #Checked in console!
#Also need to add unique id number to each item
CA$ID <- seq.int(nrow(CA))

CA$ID

#Creating table for fixed characteristics relevant to all, i.e. items asked to everything. Checked using console. 
ALL_FIXED <- CA %>% 
  select(ID, V1,	V2,	V3a,	V3b,	V3c, date,	V4,	V5, V6,	V6_cleaned, NL1a : NL1f, V7, V8a, V8b, V9,V11, V12, V13, V14, V15a_TEXT : V15f_TEXT, V15_a_cleaned : V15_f_cleaned,  V16a : V16f, NL7a : NL7e, NL24, NL25, NL26, NL27, NL28a, NL28b, NL29a : NL29g, NL30, NL31, NL32a : NL32g, NL33) #Include V's asked for all

#pull apart column V6_cleaned into two columns by splitting at the ":" 
ALL_FIXED <- separate(ALL_FIXED, V6_cleaned, into = c("V6Topic", "V6Topicdescription"), sep = ":")

#Creating Newspaper fixed characteristics table. Note: nu.nl is included as a newspaper, because it is treated as one in the codebook. Keeping V4 as article ID for primary key, also keeping V4 (outlet) as may be useful also. In addition, note that the belgium outlets are included as they're treated as newspapers. These
#need to probably be removed if neccessary during later analysis!
CA_FIXED_NP <- CA %>%
  filter(V4 != "NOS Journaal" & V4 != "RTL Nieuws")%>% #Exclude (filter out) the two TV channels
  select(ID, V2,	V4, NP1,	NP2,	NP3,	NP4,	NP5,	NP6,	NP7) 

#@@This should be edited if we claim PVV+50PLUS table is also similar@@@Creating Table for the Muslim/Polish questions, which have very different structure to the rest of data
#NL2_1_1: NL2_4_3 = the table questions on p. 11 of codebook concerning muslims, and NL4 starting items are
#for the sae q's but Polish. Articles had these questions based on their primary topic, as stated on p. 10 of 
# the codebook '(V6) = [0124 | 0501 thru 0507 | 0704 | 1204 | 1603]'. Therefore only articles/news with these 
#topics are included in this table. It also includes their ID number and primary topic as keys @@??

MUS_POL <- CA %>%
  select(ID, V2, V6, NL2_1_1 : NL2_4_3, NL3, NL4_1_1 : NL4_4_3, NL5) %>%
  filter(V6 == "Economy: Free movement of people within the EU (common market: including the Schengen agreement)" | V6 == "Immigration : EU immigration policy - regulating immigration from outside the EU (e.g. refugees, asylum, EU border" | V6 == "Immigration : Migration / immigration policy – regulating migration within the EU (e.g. labour migration from East" | V6 == "Immigration : Immigration policy (non-EU) - regulating immigration from outside the EU" | V6 == "Immigration : Immigrant integration" | V6 =="Immigration : Multiculturalism (cultural diversity, cultural plurality)" | V6 == "Immigration : Anti-Islam" | V6 == "Immigration : Other immigration topics" | V6 == "Culture and Other: Religion" | V6 == "Citizens’ rights: Immigrant rights" | V6 == "Elections: Media coverage of the campaign") 

#create variable "Origins" as factor with levels of different Nationalities: Muslims / followers of Islam, Moroccan origins, Turkish origins, Other national origins, Poles, Other specific Middle or Eastern nationals (from the EU), Middle and/or Eastern Europeans in general  (from the EU), Eastern European, but not EU (Russia, Ukraine, Belarus, Moldova)

#create variable "origin" with value 1 to 8 for different origins in variables NL2_1_1:NL2_4_3 and NL4_1_1:NL4_4_3

#levels: 1 = Muslims/followers of Islam, 2 = Moroccan origins, 3 = Turkish origins, 4 = Other national origins, 5 = Poles, 6 = other specific middle or eastern nationals (from the EU)

getOrigin <- function(datatable) {
  case_when(
    datatable$NL2_1_1 == 1 ~ 1,
    datatable$NL2_1_2 == 1 ~ 1,
    datatable$NL2_1_3 == 1 ~ 1, 
    datatable$NL2_2_1 == 1 ~ 2,
    datatable$NL2_2_2 == 1 ~ 2,
    datatable$NL2_2_3 == 1 ~ 2, 
    datatable$NL2_3_1 == 1 ~ 3,
    datatable$NL2_3_2 == 1 ~ 3,
    datatable$NL2_3_3 == 1 ~ 3,
    datatable$NL2_4_1 == 1 ~ 4,
    datatable$NL2_4_2 == 1 ~ 4,
    datatable$NL2_4_3 == 1 ~ 4,
    datatable$NL4_1_1 == 1 ~ 5,
    datatable$NL4_1_2 == 1 ~ 5,
    datatable$NL4_1_3 == 1 ~ 5, 
    datatable$NL4_2_1 == 1 ~ 6,
    datatable$NL4_2_2 == 1 ~ 6,
    datatable$NL4_2_3 == 1 ~ 6,
    datatable$NL4_3_1 == 1 ~ 7,
    datatable$NL4_3_2 == 1 ~ 7,
    datatable$NL4_3_3 == 1 ~ 7, 
    datatable$NL4_4_1 == 1 ~ 8,
    datatable$NL4_4_2 == 1 ~ 8,
    datatable$NL4_4_3 == 1 ~ 8
    )
}

#call function origin
origin <-  getOrigin(MUS_POL)
MUS_POL$origin <- origin

#do the same for location
#Levels: 1 = in the Netherlands, 2 = In another country, 3 = in the "home" country

getLocation <- function(datatable) {
  case_when(
    datatable$NL2_1_1 == 1 ~ 1,
    datatable$NL2_1_2 == 1 ~ 2,
    datatable$NL2_1_3 == 1 ~ 3,
    datatable$NL2_2_1 == 1 ~ 1,
    datatable$NL2_2_2 == 1 ~ 2,
    datatable$NL2_2_3 == 1 ~ 3,
    datatable$NL2_3_1 == 1 ~ 1,
    datatable$NL2_3_2 == 1 ~ 2,
    datatable$NL2_3_3 == 1 ~ 3,
    datatable$NL2_4_1 == 1 ~ 1,
    datatable$NL2_4_2 == 1 ~ 2,
    datatable$NL2_4_3 == 1 ~ 3,
    datatable$NL4_2_1 == 1 ~ 1,
    datatable$NL4_2_2 == 1 ~ 2,
    datatable$NL4_2_3 == 1 ~ 3,
    datatable$NL4_3_1 == 1 ~ 1,
    datatable$NL4_3_2 == 1 ~ 2,
    datatable$NL4_3_3 == 1 ~ 3,
    datatable$NL4_1_1 == 1 ~ 1,
    datatable$NL4_1_2 == 1 ~ 2,
    datatable$NL4_1_3 == 1 ~ 3
  )
}

#call function location
location <-  getLocation(MUS_POL)
MUS_POL$location <- location

#do the same for evaluation
#as in Codebook, Levels: 1 = no evaluation, 2 = negative, 3= rather negative, 4 = balanced/mixed, 5 = rather positive, 6 = positive

getEvaluation <- function(datatable) {
  case_when(
    !is.na(datatable$NL3) ~ datatable$NL3,
    !is.na(datatable$NL5) ~ datatable$NL5
  )
}

#call function evaluation
MUS_POL$evaluation <-  getEvaluation(MUS_POL)

#remove unnecessary variables
MUS_POL$NL2_1_1 <- NULL
MUS_POL$NL2_1_2 <- NULL
MUS_POL$NL2_1_3 <- NULL
MUS_POL$NL2_2_1 <- NULL
MUS_POL$NL2_2_2 <- NULL
MUS_POL$NL2_2_3 <- NULL
MUS_POL$NL2_3_1 <- NULL
MUS_POL$NL2_3_2 <- NULL
MUS_POL$NL2_3_3 <- NULL
MUS_POL$NL2_4_1 <- NULL
MUS_POL$NL2_4_2 <- NULL
MUS_POL$NL2_4_3 <- NULL

MUS_POL$NL3 <- NULL

MUS_POL$NL4_1_1 <- NULL
MUS_POL$NL4_1_2 <- NULL
MUS_POL$NL4_1_3 <- NULL
MUS_POL$NL4_2_1 <- NULL
MUS_POL$NL4_2_2 <- NULL
MUS_POL$NL4_2_3 <- NULL
MUS_POL$NL4_3_1 <- NULL
MUS_POL$NL4_3_2 <- NULL
MUS_POL$NL4_3_3 <- NULL
MUS_POL$NL4_4_1 <- NULL
MUS_POL$NL4_4_2 <- NULL
MUS_POL$NL4_4_3 <- NULL

MUS_POL$NL5 <- NULL

CA_FIXED_TV <- CA %>%
  filter(V4 == "NOS Journaal" | V4 == "RTL Nieuws")%>% #Exclude (filter out) the newspapers
  select(V2,	V4, TV1, TV2)


APRIL <- CA %>% #Table with variables coded only after april the 17th 
  select(V2, date, V9,	V9b,	V10a : V10c,	NL6_1_1 : NL6_3_4,	NL8a,	NL9a_1 : NL9a_5_TEXT, NL9b_1 : NL9b_5_TEXT, NL9c1 : NL9c5_TEXT, NL9d1 : NL9d5_TEXT,	NL10a : NL10d, NL11a1 : NL23d5_TEXT,	NL34 : NL41f, NL42a_a : NL42b_SP_f, NL43, NL44, NL45 : NL47) %>% 
filter(date >= as.Date("2014-04-17")) #and include cases only after filtered date, 17th April

  

```

```{r}
#Creating a table for the PVV 50PLUS articles. 
#NOTE: This table @@was not further tidied as tidying would be similar to what was demonstrated with the MUS/POLE table above.
#Therefore, variables required by group members for their own analyses were tidied as required, rather than restructuring this entire table. 
#See for example PVVH table used by Haylee. 

PVV50 <- CA %>% #@@Ask whether we have to totally redo this table or not.
  filter(date >= as.Date("2014-04-17"))%>% #and include cases only after filtered date, 17th April
  dplyr::select(V2, NL8a, NL8b, NL8c, NL8d, NL9a_1:NL9a_5_TEXT, NL9b_1:NL9b_5_TEXT, NL9c1:NL9c5_TEXT, NL9d1:NL9d5_TEXT, NL10a, NL10b, NL10c, NL10d, NL11a1:NL11a5_TEXT, NL11b1:NL11b5_TEXT, NL11c1:NL11c5_TEXT, NL11d1:NL11d5_TEXT, NL12a, NL12b, NL12c, NL12d, NL13a1:NL13a5_TEXT, NL13b1:NL13b5_TEXT, NL13c1:NL13c5_TEXT, NL13d1:NL13d5_TEXT, NL14a, NL14b, NL14c, NL14d,  NL15a1:NL15a5_TEXT, NL15b1:NL15b5_TEXT, NL15c1:NL15c5_TEXT, NL15d1:NL15d5_TEXT, NL16a, NL16b, NL16c, NL16d, NL17a1:NL17a5_TEXT, NL17b1:NL17b5_TEXT, NL17c1:NL17c5_TEXT, NL17d1:NL17d5_TEXT, NL18a, NL18b, NL18c, NL18d, NL19a1:NL19a5_TEXT, NL19b1:NL19b5_TEXT, NL19c1:NL19c5_TEXT, NL19d1:NL19d5_TEXT, NL20a, NL20b, NL20c, NL20d, NL21a1:NL21a5_TEXT, NL21b1:NL21b5_TEXT, NL21c1:NL21c5_TEXT, NL21d1:NL21d5_TEXT, NL22a, NL22b, NL22c, NL22d, NL23a1:NL23a5_TEXT, NL23b1:NL23b5_TEXT, NL23c1:NL23c5_TEXT, NL23d1:NL23d5_TEXT)




  
```

```{r}
#Creating a new object MAT with the Wavevalue variable, indicating in which Wave the observation was collected for each case.
MAT <- ESSclean %>%
  select(Wavevalue) 
#Using the stripper function in order to treat data about anti-immigration attitudes as numeric and be able to use only the numerical number from the observations (E.g. '1 helemaal mee eens' becomes 1).

stripper <- function(string){ 
  str_extract(string, "\\-*\\d+\\.*\\d*")
}
#Adding columns for the anti-immigration attitudes as umeric and then recode them as 1 when the attitudes is 5 or higher towards a negative attitude.
MAT <- MAT%>%
  mutate(antiimm1 = as.numeric(stripper(w1_q42_1))) %>%
  mutate(antiimm2 = as.numeric(stripper(w1_q42_2))) %>%
  mutate(antiimm3 = as.numeric(stripper(w1_q42_3))) %>%
  mutate(antiimm4 = as.numeric(stripper(w1_q42_4))) %>%
   mutate(antiimm5 = as.numeric(stripper(w2_q39_1 ))) %>%
   mutate(antiimm6 = as.numeric(stripper(w2_q39_2))) %>%
   mutate(antiimm7 = as.numeric(stripper(w2_q39_3))) %>%
  mutate(antiimm8 = as.numeric(stripper(w2_q39_4))) %>%
  mutate(antiimm1 =ifelse(antiimm1 < 4, 1, 0)) %>%
  mutate(antiimm2 =ifelse(antiimm2 < 4, 1, 0)) %>%
  mutate(antiimm3 =ifelse(antiimm3 > 4, 1, 0)) %>%
  mutate(antiimm4 =ifelse(antiimm4 < 4, 1, 0)) %>%
  mutate(antiimm5 =ifelse(antiimm5 < 4, 1, 0)) %>%
  mutate(antiimm6 =ifelse(antiimm6 < 4, 1, 0)) %>%
  mutate(antiimm7 =ifelse(antiimm7 > 4, 1, 0)) %>%
  mutate(antiimm8 =ifelse(antiimm8 < 4, 1, 0))


#Adding the variables for political knowledge to the object MAT, recoding them as 1 (for a correct answer) and 0 (for an uncorrect one)
MAT <- ESSclean %>%
mutate(Plknowl1_1 = ifelse(PolKnowl1 == "Frans Timmermans", 1, 0)) %>%
mutate(Plknowl1_2 = ifelse(PolKnowl2 == "4 jaar", 1, 0)) %>%
mutate(Plknowl1_3 = ifelse(PolKnowl3 == 26 , 1, 0)) %>%
mutate(Plknowl1_4 = ifelse(PolKnowl4 == 28, 1, 0)) %>%
mutate(Plknowl1_5 = ifelse(PolKnowl5 == "Martin Schulz", 1, 0)) 

#Creating variables "PoliticalKnowledge" and "AntiImmigrationLevel" computing the means of the scores from the questions about anti-immigrant attitudes and political knowledge. Political knowledge has already been recoded in order to be relating to the cases by view (PoKnowl1 is displaying values for wave 1, PolKnowl2 for wave 2 etc.)
MAT$PoliticalKnowledge <- rowMeans(subset(MAT, select = c(Plknowl1_1, Plknowl1_2, Plknowl1_3, Plknowl1_4, Plknowl1_5)), na.rm = TRUE)

MAT$AntiImmigrationLevel <- rowMeans(subset(MAT, select = c(antiimm1, antiimm2, antiimm3, antiimm4, antiimm5, antiimm6, antiimm7, antiimm8)), na.rm = TRUE)


#Creating a dataframe with the three variables of interest
MAT2 <-  MAT %>%
  select(AntiImmigrationLevel, PoliticalKnowledge, Wavevalue)

#Installing plotly and uploading plotly and tidyverse
install.packages("plotly")
library(plotly)
library(tidyverse)

#Filtering by the first two waves, since anti-immigrant attitudes were only calculated during the 1st and 2nd wave.
MAT2 <- MAT2 %>%
  filter(Wavevalue == 1 | Wavevalue == 2)

#Creating a plot with the geom_bin
p <- ggplot(data = MAT2, aes(x = PoliticalKnowledge, y = AntiImmigrationLevel)) +
  geom_bin2d(bins =6, color = "white") +
  scale_fill_gradient(low = "#00AFBB", high = "#FC4E07")+
  theme_minimal()  + facet_wrap(~Wavevalue)

#Displaying the final plot
p <- ggplotly(p)
p




```

